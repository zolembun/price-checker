import streamlit as st
import pandas as pd
import google.generativeai as genai
from google.oauth2.service_account import Credentials
from googleapiclient.discovery import build
import urllib.parse
from datetime import datetime
import re
import json
import time

# ---------------------------------------------------------
# 1. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö (‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÅ‡∏£‡∏Å‡∏™‡∏∏‡∏î ‡∏´‡πâ‡∏≤‡∏°‡∏¢‡πâ‡∏≤‡∏¢)
# ---------------------------------------------------------
st.set_page_config(page_title="‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏ä‡πá‡∏Ñ‡∏£‡∏≤‡∏Ñ‡∏≤ & AI", page_icon="üí∞", layout="wide")

# ---------------------------------------------------------
# 2. ‡∏£‡∏∞‡∏ö‡∏ö Login
# ---------------------------------------------------------
def check_password():
    def password_entered():
        if st.session_state["password"] == st.secrets["app_password"]:
            st.session_state["password_correct"] = True
            del st.session_state["password"]
        else:
            st.session_state["password_correct"] = False

    if "password_correct" not in st.session_state:
        st.header("üîí ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏£‡∏∞‡∏ö‡∏ö")
        st.text_input("‡πÉ‡∏™‡πà‡∏£‡∏´‡∏±‡∏™‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô", type="password", on_change=password_entered, key="password")
        return False
    elif not st.session_state["password_correct"]:
        st.header("üîí ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏£‡∏∞‡∏ö‡∏ö")
        st.text_input("‡πÉ‡∏™‡πà‡∏£‡∏´‡∏±‡∏™‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô", type="password", on_change=password_entered, key="password")
        st.error("‚ùå ‡∏£‡∏´‡∏±‡∏™‡∏ú‡πà‡∏≤‡∏ô‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á")
        return False
    else:
        return True

if not check_password():
    st.stop()

# ---------------------------------------------------------
# 3. CSS Styling (‡∏£‡∏ß‡∏°‡∏™‡∏ß‡∏¢‡πÜ ‡πÑ‡∏ß‡πâ‡∏ó‡∏µ‡πà‡πÄ‡∏î‡∏µ‡∏¢‡∏ß)
# ---------------------------------------------------------
st.markdown("""
<style>
    /* ‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏∏‡∏ô */
    .cost-box { 
        background-color: #ffebee; padding: 15px; border-radius: 10px; 
        border: 2px solid #ef5350; text-align: center; box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    }
    .price-value-cost { font-size: 42px !important; font-weight: 900; color: #c62828; line-height: 1.2;}
    
    /* ‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏£‡∏≤‡∏Ñ‡∏≤‡∏Ç‡∏≤‡∏¢ */
    .selling-box { 
        background-color: #e8f5e9; padding: 15px; border-radius: 10px; 
        border: 2px solid #66bb6a; text-align: center;
    }
    .price-value-sell { font-size: 42px !important; font-weight: 900; color: #2e7d32; line-height: 1.2;}
    
    /* ‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• */
    .info-box {
        background-color: #f8f9fa; padding: 15px; border-radius: 10px; border: 1px solid #ddd;
    }
    
    /* ‡∏õ‡∏∏‡πà‡∏°‡∏Å‡∏î */
    div.stButton > button { width: 100%; border-radius: 8px; font-weight: bold; height: 3em; }
    
    /* ‡∏ã‡πà‡∏≠‡∏ô Header */
    header {visibility: hidden;}
    
    /* Status Widget */
    .stStatusWidget { border-radius: 10px; }
</style>
""", unsafe_allow_html=True)

# ---------------------------------------------------------
# 4. ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Services (Connecting)
# ---------------------------------------------------------
@st.cache_resource
def init_services():
    try:
        service_account_info = st.secrets["gcp_service_account"]
        gemini_key = st.secrets["gemini_api_key"]
        
        scopes = ['https://www.googleapis.com/auth/spreadsheets', 
                  'https://www.googleapis.com/auth/drive.metadata.readonly']
        creds = Credentials.from_service_account_info(service_account_info, scopes=scopes)
        
        sheets_service = build('sheets', 'v4', credentials=creds)
        drive_service = build('drive', 'v3', credentials=creds)
        genai.configure(api_key=gemini_key)
        model = genai.GenerativeModel('gemini-1.5-flash')
        
        return sheets_service, drive_service, model
    except Exception as e:
        st.error(f"Config Error: {e}")
        return None, None, None

sheets_svc, drive_svc, ai_model = init_services()
if not sheets_svc: st.stop()

try:
    SHEET_URL = st.secrets["sheet_url"]
    SPREADSHEET_ID = SHEET_URL.split('/d/')[1].split('/')[0]
except:
    st.error("‡πÑ‡∏°‡πà‡∏û‡∏ö sheet_url ‡πÉ‡∏ô Secrets")
    st.stop()

# ---------------------------------------------------------
# 5. ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÇ‡∏´‡∏•‡∏î/‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Data Management)
# ---------------------------------------------------------
@st.cache_data(ttl=600)
def load_data_master():
    try:
        # Metadata
        file_meta = drive_svc.files().get(fileId=SPREADSHEET_ID, fields="name, modifiedTime").execute()
        file_name = file_meta.get('name')
        dt = datetime.strptime(file_meta.get('modifiedTime'), "%Y-%m-%dT%H:%M:%S.%fZ")
        last_update = dt.strftime("%d/%m/%Y %H:%M ‡∏ô.")

        # Main Data
        res_main = sheets_svc.spreadsheets().values().get(spreadsheetId=SPREADSHEET_ID, range="A:H").execute()
        vals_main = res_main.get('values', [])
        
        if vals_main:
            df_main = pd.DataFrame(vals_main[1:], columns=vals_main[0])
            for col in ['‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏∏‡∏ô‡∏ï‡πà‡∏≠‡∏´‡∏ô‡πà‡∏ß‡∏¢', '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏ï‡πâ‡∏≠‡∏Å']:
                if col in df_main.columns:
                    df_main[col] = pd.to_numeric(df_main[col].astype(str).str.replace(',', ''), errors='coerce').fillna(0)
        else:
            df_main = pd.DataFrame()

        # AI Memory Data
        try:
            res_mem = sheets_svc.spreadsheets().values().get(spreadsheetId=SPREADSHEET_ID, range="AI_Memory!A:E").execute()
            vals_mem = res_mem.get('values', [])
            if vals_mem:
                df_mem = pd.DataFrame(vals_mem[1:], columns=vals_mem[0])
            else:
                df_mem = pd.DataFrame(columns=['SKU', 'AI_Brand', 'AI_Type', 'AI_Spec', 'AI_Tags'])
        except:
            df_mem = pd.DataFrame(columns=['SKU', 'AI_Brand', 'AI_Type', 'AI_Spec', 'AI_Tags'])

        return df_main, df_mem, file_name, last_update

    except Exception as e:
        st.error(f"Load Data Error: {e}")
        return pd.DataFrame(), pd.DataFrame(), "Error", "-"

def append_to_sheet(new_data_df):
    values = new_data_df.values.tolist()
    body = {'values': values}
    try:
        sheets_svc.spreadsheets().values().append(
            spreadsheetId=SPREADSHEET_ID, range="AI_Memory!A:A", 
            valueInputOption="USER_ENTERED", body=body
        ).execute()
        return True
    except: return False

@st.cache_data(ttl=600)
def merge_data(df_main, df_mem):
    if df_mem.empty: return df_main.copy()
    df_main_c = df_main.copy()
    df_mem_c = df_mem.copy()
    df_main_c['‡∏£‡∏´‡∏±‡∏™‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤'] = df_main_c['‡∏£‡∏´‡∏±‡∏™‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤'].astype(str).str.strip()
    df_mem_c['SKU'] = df_mem_c['SKU'].astype(str).str.strip()
    return pd.merge(df_main_c, df_mem_c, left_on='‡∏£‡∏´‡∏±‡∏™‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤', right_on='SKU', how='left')

# Helper Functions
def clean_text(text):
    if not isinstance(text, str): text = str(text)
    return re.sub(r'[^a-zA-Z0-9‡∏Å-‡πô]', '', text).lower()

def ask_gemini_extract(names):
    prompt = f"‡∏™‡∏Å‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤ JSON: {json.dumps(names, ensure_ascii=False)}\nOutput JSON Array: [{{'AI_Brand':..., 'AI_Type':..., 'AI_Spec':..., 'AI_Tags':...}}]"
    try:
        res = ai_model.generate_content(prompt)
        txt = res.text.strip().replace('```json', '').replace('```', '')
        if txt.startswith('[') and txt.endswith(']'): return json.loads(txt)
        start, end = txt.find('['), txt.rfind(']') + 1
        if start != -1 and end != -1: return json.loads(txt[start:end])
        return []
    except: return []

def ask_gemini_filter(query, cols):
    prompt = f"‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° '{query}' ‡πÄ‡∏õ‡πá‡∏ô JSON Filter Pandas. Cols: {cols}. Format: {{'filters': [{{'column':..., 'operator':..., 'value':...}}]}}"
    try:
        res = ai_model.generate_content(prompt)
        return json.loads(res.text.strip().replace('```json', '').replace('```', ''))
    except: return None

# ---------------------------------------------------------
# 6. MAIN APP UI (TABS)
# ---------------------------------------------------------

# ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏ó‡∏±‡πâ‡∏á 2 ‡πÅ‡∏ó‡πá‡∏ö
df_main, df_mem, file_name, last_update = load_data_master()

st.title("üí∞ ‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏ä‡πá‡∏Ñ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤ & AI")
st.caption(f"üìÇ ‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {file_name} | üïí ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î: {last_update}")

# ‡∏™‡∏£‡πâ‡∏≤‡∏á TAB ‡πÄ‡∏°‡∏ô‡∏π
tab1, tab2 = st.tabs(["üè† ‡πÄ‡∏ä‡πá‡∏Ñ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏£‡∏≤‡∏¢‡∏ï‡∏±‡∏ß (Code/Name)", "ü§ñ ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞ (AI Search)"])

# =========================================================
# TAB 1: ‡πÄ‡∏ä‡πá‡∏Ñ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏£‡∏≤‡∏¢‡∏ï‡∏±‡∏ß (Logic ‡∏´‡∏ô‡πâ‡∏≤ 1 ‡πÄ‡∏î‡∏¥‡∏° + ‡∏≠‡∏±‡∏õ‡πÄ‡∏Å‡∏£‡∏î)
# =========================================================
with tab1:
    st.info("üí° ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö: ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏£‡∏π‡πâ '‡∏£‡∏´‡∏±‡∏™‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤' ‡∏´‡∏£‡∏∑‡∏≠ '‡∏ä‡∏∑‡πà‡∏≠‡∏£‡∏∏‡πà‡∏ô' ‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡πà‡∏ô‡∏≠‡∏ô")
    
    query1 = st.text_input("‡∏û‡∏¥‡∏°‡∏û‡πå‡∏£‡∏´‡∏±‡∏™‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤ ‡∏´‡∏£‡∏∑‡∏≠ ‡∏ä‡∏∑‡πà‡∏≠‡∏£‡∏∏‡πà‡∏ô", placeholder="‡πÄ‡∏ä‡πà‡∏ô rt20, parsr5lae (‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏™‡πà‡∏Ç‡∏µ‡∏î)", key="search_tab1")
    
    if query1:
        match_index = -1
        found_by = ""
        
        # Smart Search Logic
        query_clean = clean_text(query1)
        sku_clean_series = df_main['‡∏£‡∏´‡∏±‡∏™‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤'].astype(str).apply(clean_text)
        desc_clean_series = df_main['‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤'].astype(str).apply(clean_text)
        
        # ‡∏î‡πà‡∏≤‡∏ô 1: ‡∏£‡∏´‡∏±‡∏™‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤
        sku_matches = df_main[sku_clean_series.str.contains(query_clean, na=False)]
        if not sku_matches.empty:
            match_index = sku_matches.index[0]
            found_by = "‚ö° ‡πÄ‡∏à‡∏≠‡∏£‡∏´‡∏±‡∏™‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤"
        else:
            # ‡∏î‡πà‡∏≤‡∏ô 2: ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î
            desc_matches = df_main[desc_clean_series.str.contains(query_clean, na=False)]
            if not desc_matches.empty:
                match_index = desc_matches.index[0]
                found_by = "üîé ‡πÄ‡∏à‡∏≠‡πÉ‡∏ô‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î"
            else:
                # ‡∏î‡πà‡∏≤‡∏ô 3: AI Helper
                keywords = list(filter(None, re.split(r'[^a-zA-Z0-9]', query1)))
                if not keywords: keywords = [query1]
                candidates = df_main[df_main.astype(str).apply(lambda x: any(k.lower() in x.lower() for k in keywords), axis=1)]
                
                if candidates.empty: search_pool = df_main.sample(min(len(df_main), 15))
                else: search_pool = candidates.head(30)
                
                prod_str = search_pool[['‡∏£‡∏´‡∏±‡∏™‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤', '‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤']].to_string(index=True)
                with st.spinner('ü§ñ AI ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ä‡πà‡∏ß‡∏¢‡πÅ‡∏Å‡∏∞‡∏•‡∏≤‡∏¢‡πÅ‡∏ó‡∏á...'):
                    try:
                        res = ai_model.generate_content(f"‡∏´‡∏≤ index ‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö '{query1}' ‡∏à‡∏≤‡∏Å:\n{prod_str}\n‡∏ï‡∏≠‡∏ö‡πÅ‡∏Ñ‡πà‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç index. ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ -1")
                        match_index = int(res.text.strip())
                        found_by = "ü§ñ AI ‡∏Ñ‡πâ‡∏ô‡∏û‡∏ö"
                    except: match_index = -1

        # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• Tab 1
        if match_index != -1 and match_index in df_main.index:
            item = df_main.loc[match_index]
            cost = item.get('‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏∏‡∏ô‡∏ï‡πà‡∏≠‡∏´‡∏ô‡πà‡∏ß‡∏¢', 0)
            stock = item.get('‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏ï‡πâ‡∏≠‡∏Å', 0)
            mid = item.get('‡∏£‡∏´‡∏±‡∏™‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤', '-')
            name = item.get('‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤', '-')
            brand = item.get('‡∏¢‡∏µ‡πà‡∏´‡πâ‡∏≠', '-')

            st.success(f"{found_by}: {name}")
            
            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏≤‡∏Ñ‡∏≤
            target_margin = 12
            sell_price = cost * (1 + (target_margin/100))
            profit = sell_price - cost

            c1, c2, c3 = st.columns([1.3, 1.3, 1])
            with c1:
                st.markdown(f"""<div class="cost-box"><div style="color:#555;font-weight:bold;">üî¥ ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏∏‡∏ô</div><div class="price-value-cost">{cost:,.0f}</div></div>""", unsafe_allow_html=True)
            with c2:
                st.markdown(f"""<div class="selling-box"><div style="color:#555;font-weight:bold;">üü¢ ‡∏Ç‡∏≤‡∏¢‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ (+{target_margin}%)</div><div class="price-value-sell">{sell_price:,.0f}</div><div style="color:#1b5e20;">‡∏Å‡∏≥‡πÑ‡∏£ {profit:,.0f} ‡∏ö‡∏≤‡∏ó</div></div>""", unsafe_allow_html=True)
            with c3:
                st.markdown(f"""<div class="info-box"><b>üÜî ‡∏£‡∏´‡∏±‡∏™:</b> {mid}<br><b>üì¶ ‡∏™‡∏ï‡πâ‡∏≠‡∏Å:</b> {stock}<br><b>üè∑Ô∏è ‡∏¢‡∏µ‡πà‡∏´‡πâ‡∏≠:</b> {brand}</div>""", unsafe_allow_html=True)
                st.write("")
                g_q = urllib.parse.quote(name)
                st.link_button("üåê ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ Google", f"https://www.google.com/search?q={g_q}", use_container_width=True)

            st.divider()
            with st.expander("‡∏î‡∏π‡∏ï‡∏≤‡∏£‡∏≤‡∏á Margin (3% - 30%)", expanded=True):
                margins = [3, 5, 8, 10, 12, 15, 18, 25, 30]
                p_data = [{"‡∏Å‡∏≥‡πÑ‡∏£ %": f"{m}%", "‡∏£‡∏≤‡∏Ñ‡∏≤‡∏Ç‡∏≤‡∏¢": f"{cost*(1+m/100):,.0f}", "‡∏Å‡∏≥‡πÑ‡∏£ (‡∏ö‡∏≤‡∏ó)": f"{(cost*(1+m/100))-cost:,.0f}"} for m in margins]
                st.dataframe(pd.DataFrame(p_data), hide_index=True, use_container_width=True)

            st.divider()
            st.subheader("üõí ‡πÄ‡∏ä‡πá‡∏Ñ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏Ñ‡∏π‡πà‡πÅ‡∏Ç‡πà‡∏á (Hot Search)")
            default_search = re.sub(r'[\u0E00-\u0E7F]', '', str(mid)).strip('-').strip()
            final_kw = st.text_input("üéØ ‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤:", value=default_search, key="hot_kw")
            
            if final_kw:
                enc = urllib.parse.quote(final_kw.strip())
                stores = [
                    {"name": "HomePro", "url": f"https://www.homepro.co.th/search?q={enc}"},
                    {"name": "PowerBuy", "url": f"https://www.powerbuy.co.th/th/search/{enc}"},
                    {"name": "ThaiWatsadu", "url": f"https://www.thaiwatsadu.com/th/search/{enc}"},
                    {"name": "Big C", "url": f"https://www.bigc.co.th/search?q={enc}"},
                    {"name": "Global", "url": f"https://globalhouse.co.th/search?keyword={enc}"},
                    {"name": "Makro", "url": f"https://www.makro.pro/c/search?q={enc}"},
                    {"name": "Dohome", "url": f"https://www.dohome.co.th/search?q={enc}"},
                    {"name": "Shopee", "url": f"https://shopee.co.th/search?keyword={enc}"},
                    {"name": "Lazada", "url": f"https://www.lazada.co.th/catalog/?q={enc}"},
                ]
                
                # --- ‡∏à‡∏±‡∏î‡∏õ‡∏∏‡πà‡∏°‡πÄ‡∏õ‡πá‡∏ô 2 ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå ---
                cols = st.columns(2)
                for i, s in enumerate(stores):
                    with cols[i%2]: st.link_button(f"üîç {s['name']}", s['url'], use_container_width=True)
        else:
            if query1: st.warning(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤: '{query1}'")

# =========================================================
# TAB 2: ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞ AI (Logic ‡∏´‡∏ô‡πâ‡∏≤ 2 ‡πÄ‡∏î‡∏¥‡∏°)
# =========================================================
with tab2:
    st.info("üí° ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö: ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏ö‡∏ö‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ ‡πÄ‡∏ä‡πà‡∏ô '‡∏ó‡∏µ‡∏ß‡∏µ Samsung ‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡∏´‡∏°‡∏∑‡πà‡∏ô', '‡πÅ‡∏≠‡∏£‡πå inverter'")
    
    # ‡∏™‡πà‡∏ß‡∏ô‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ AI
    processed_skus = df_mem['SKU'].astype(str).str.strip().tolist() if not df_mem.empty else []
    new_items_df = df_main[~df_main['‡∏£‡∏´‡∏±‡∏™‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤'].astype(str).str.strip().isin(processed_skus)]
    new_count = len(new_items_df)
    
    with st.expander(f"‚öôÔ∏è ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏™‡∏°‡∏≠‡∏á AI ({len(df_mem)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÅ‡∏•‡πâ‡∏ß)"):
        c_a1, c_a2 = st.columns([3, 1])
        c_a1.write(f"‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà AI ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å: **{new_count}** ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
        
        if new_count > 0:
            if c_a2.button("üöÄ ‡∏™‡∏≠‡∏ô AI ‡πÄ‡∏î‡∏µ‡πã‡∏¢‡∏ß‡∏ô‡∏µ‡πâ", type="primary"):
                with st.status("ü§ñ AI ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ...", expanded=True) as status:
                    to_proc = new_items_df[['‡∏£‡∏´‡∏±‡∏™‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤', '‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤']].rename(columns={'‡∏£‡∏´‡∏±‡∏™‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤':'SKU', '‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤':'Name'}).to_dict('records')
                    BATCH = 10
                    res_save = []
                    total_batches = (len(to_proc) // BATCH) + 1
                    
                    for i in range(0, len(to_proc), BATCH):
                        chunk = to_proc[i:i+BATCH]
                        status.write(f"Batch {(i//BATCH)+1}/{total_batches} ({len(chunk)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)...")
                        names = [x['Name'] for x in chunk]
                        ai_res = ask_gemini_extract(names)
                        for idx, item in enumerate(chunk):
                            ar = ai_res[idx] if idx < len(ai_res) else {}
                            res_save.append([item['SKU'], ar.get('AI_Brand','Unknown'), ar.get('AI_Type','Other'), ar.get('AI_Spec','-'), ar.get('AI_Tags','')])
                        time.sleep(4)
                    
                    if res_save:
                        append_to_sheet(pd.DataFrame(res_save))
                        status.update(label="‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!", state="complete")
                        st.balloons()
                        st.cache_data.clear()
                        time.sleep(1)
                        st.rerun()
        else:
            c_a2.button("üîÑ ‡∏£‡∏µ‡πÇ‡∏´‡∏•‡∏î", on_click=lambda: st.cache_data.clear())

    st.divider()
    
    # Interface ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ AI
    df_search = merge_data(df_main, df_mem)
    
    col_q1, col_q2 = st.columns([4, 1])
    query2 = col_q1.text_input("‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏ö‡∏ö‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥", placeholder="‡πÄ‡∏ä‡πà‡∏ô ‡∏ï‡∏π‡πâ‡πÄ‡∏¢‡πá‡∏ô 2 ‡∏õ‡∏£‡∏∞‡∏ï‡∏π ‡∏£‡∏≤‡∏Ñ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 8000", key="search_tab2")
    if col_q2.button("‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ AI", type="primary"):
        if query2:
            with st.spinner('ü§ñ AI ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡∏¥‡∏î...'):
                cols_ai = ['AI_Brand', 'AI_Type', 'AI_Spec', 'AI_Tags', '‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏∏‡∏ô‡∏ï‡πà‡∏≠‡∏´‡∏ô‡πà‡∏ß‡∏¢']
                filters = ask_gemini_filter(query2, cols_ai)
                
                if filters and 'filters' in filters:
                    mask = pd.Series([True] * len(df_search))
                    active_conds = []
                    try:
                        for f in filters['filters']:
                            col, op, val = f['column'], f['operator'], f['value']
                            if col not in df_search.columns: continue
                            active_conds.append(f"{col} {op} {val}")
                            
                            s_val = pd.to_numeric(df_search[col], errors='coerce').fillna(0) if col == '‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏∏‡∏ô‡∏ï‡πà‡∏≠‡∏´‡∏ô‡πà‡∏ß‡∏¢' else df_search[col].astype(str)
                            val = float(val) if col == '‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏∏‡∏ô‡∏ï‡πà‡∏≠‡∏´‡∏ô‡πà‡∏ß‡∏¢' else str(val)
                            
                            if op == 'contains': mask &= s_val.str.contains(val, case=False, na=False)
                            elif op == 'equals': mask &= (s_val == val)
                            elif op == 'gt': mask &= (s_val > val)
                            elif op == 'lt': mask &= (s_val < val)
                        
                        results = df_search[mask]
                        if not results.empty:
                            st.success(f"‚úÖ ‡∏û‡∏ö {len(results)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
                            st.dataframe(
                                results[['‡∏£‡∏´‡∏±‡∏™‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤', '‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤', '‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏∏‡∏ô‡∏ï‡πà‡∏≠‡∏´‡∏ô‡πà‡∏ß‡∏¢', '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏ï‡πâ‡∏≠‡∏Å', 'AI_Brand', 'AI_Spec']],
                                column_config={
                                    "‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏∏‡∏ô‡∏ï‡πà‡∏≠‡∏´‡∏ô‡πà‡∏ß‡∏¢": st.column_config.NumberColumn("‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏∏‡∏ô", format="‡∏ø%d"), 
                                    "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏ï‡πâ‡∏≠‡∏Å": st.column_config.ProgressColumn("‡∏™‡∏ï‡πâ‡∏≠‡∏Å", format="%d", max_value=int(df_search['‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏ï‡πâ‡∏≠‡∏Å'].max()))
                                },
                                use_container_width=True, hide_index=True
                            )
                        else: st.warning(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤ (‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç: {', '.join(active_conds)})")
                    except: st.error("‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏≠‡∏á")
                else:
                    # Fallback
                    simple = df_search.astype(str).apply(lambda x: x.str.contains(query2, case=False)).any(axis=1)
                    st.dataframe(df_search[simple], use_container_width=True)
