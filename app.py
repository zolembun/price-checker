import streamlit as st
import pandas as pd
import google.generativeai as genai
from google.oauth2.service_account import Credentials
from googleapiclient.discovery import build
import urllib.parse
from datetime import datetime
import re
import json
import time

# ---------------------------------------------------------
# 1. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö (‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÅ‡∏£‡∏Å‡∏™‡∏∏‡∏î ‡∏´‡πâ‡∏≤‡∏°‡∏¢‡πâ‡∏≤‡∏¢)
# ---------------------------------------------------------
st.set_page_config(page_title="‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏ä‡πá‡∏Ñ‡∏£‡∏≤‡∏Ñ‡∏≤ & AI", page_icon="üí∞", layout="wide")

# ---------------------------------------------------------
# 2. ‡∏£‡∏∞‡∏ö‡∏ö Login
# ---------------------------------------------------------
def check_password():
    def password_entered():
        if st.session_state["password"] == st.secrets["app_password"]:
            st.session_state["password_correct"] = True
            del st.session_state["password"]
        else:
            st.session_state["password_correct"] = False

    if "password_correct" not in st.session_state:
        st.header("üîí ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏£‡∏∞‡∏ö‡∏ö")
        st.text_input("‡πÉ‡∏™‡πà‡∏£‡∏´‡∏±‡∏™‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô", type="password", on_change=password_entered, key="password")
        return False
    elif not st.session_state["password_correct"]:
        st.header("üîí ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏£‡∏∞‡∏ö‡∏ö")
        st.text_input("‡πÉ‡∏™‡πà‡∏£‡∏´‡∏±‡∏™‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô", type="password", on_change=password_entered, key="password")
        st.error("‚ùå ‡∏£‡∏´‡∏±‡∏™‡∏ú‡πà‡∏≤‡∏ô‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á")
        return False
    else:
        return True

if not check_password():
    st.stop()

# ---------------------------------------------------------
# 3. CSS Styling
# ---------------------------------------------------------
st.markdown("""
<style>
    /* ‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏∏‡∏ô */
    .cost-box { 
        background-color: #ffebee; padding: 15px; border-radius: 10px; 
        border: 2px solid #ef5350; text-align: center; box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    }
    .price-value-cost { font-size: 42px !important; font-weight: 900; color: #c62828; line-height: 1.2;}
    
    /* ‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏£‡∏≤‡∏Ñ‡∏≤‡∏Ç‡∏≤‡∏¢ */
    .selling-box { 
        background-color: #e8f5e9; padding: 15px; border-radius: 10px; 
        border: 2px solid #66bb6a; text-align: center;
    }
    .price-value-sell { font-size: 42px !important; font-weight: 900; color: #2e7d32; line-height: 1.2;}
    
    /* ‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• */
    .info-box {
        background-color: #f8f9fa; padding: 15px; border-radius: 10px; border: 1px solid #ddd;
    }
    
    /* ‡∏õ‡∏∏‡πà‡∏°‡∏Å‡∏î */
    div.stButton > button { width: 100%; border-radius: 8px; font-weight: bold; height: 3em; }
    
    /* ‡∏ã‡πà‡∏≠‡∏ô Header */
    header {visibility: hidden;}
    
    /* Status Widget */
    .stStatusWidget { border-radius: 10px; }
</style>
""", unsafe_allow_html=True)

# ---------------------------------------------------------
# 4. ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Services
# ---------------------------------------------------------
@st.cache_resource
def init_services():
    try:
        service_account_info = st.secrets["gcp_service_account"]
        gemini_key = st.secrets["gemini_api_key"]
        
        scopes = ['https://www.googleapis.com/auth/spreadsheets', 
                  'https://www.googleapis.com/auth/drive.metadata.readonly']
        creds = Credentials.from_service_account_info(service_account_info, scopes=scopes)
        
        sheets_service = build('sheets', 'v4', credentials=creds)
        drive_service = build('drive', 'v3', credentials=creds)
        
        # Config Gemini
        genai.configure(api_key=gemini_key)
        
        # üî• ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà Error: ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏∏‡πà‡∏ô Latest
        try:
            model = genai.GenerativeModel('gemini-2.0-flash')
        except:
            # Fallback ‡∏ñ‡πâ‡∏≤ latest ‡πÉ‡∏ä‡πâ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‡πÉ‡∏´‡πâ‡∏•‡∏≠‡∏á‡∏ï‡∏±‡∏ß‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤‡∏´‡∏£‡∏∑‡∏≠ Pro
            model = genai.GenerativeModel('gemini-2.0-flash')
        
        return sheets_service, drive_service, model
    except Exception as e:
        st.error(f"Config Error: {e}")
        return None, None, None

sheets_svc, drive_svc, ai_model = init_services()
if not sheets_svc: st.stop()

try:
    SHEET_URL = st.secrets["sheet_url"]
    SPREADSHEET_ID = SHEET_URL.split('/d/')[1].split('/')[0]
except:
    st.error("‡πÑ‡∏°‡πà‡∏û‡∏ö sheet_url ‡πÉ‡∏ô Secrets")
    st.stop()

# ---------------------------------------------------------
# 5. ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÇ‡∏´‡∏•‡∏î/‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
# ---------------------------------------------------------
@st.cache_data(ttl=600)
def load_data_master():
    try:
        # Metadata
        file_meta = drive_svc.files().get(fileId=SPREADSHEET_ID, fields="name, modifiedTime").execute()
        file_name = file_meta.get('name')
        dt = datetime.strptime(file_meta.get('modifiedTime'), "%Y-%m-%dT%H:%M:%S.%fZ")
        last_update = dt.strftime("%d/%m/%Y %H:%M ‡∏ô.")

        # Main Data
        res_main = sheets_svc.spreadsheets().values().get(spreadsheetId=SPREADSHEET_ID, range="A:H").execute()
        vals_main = res_main.get('values', [])
        
        if vals_main:
            df_main = pd.DataFrame(vals_main[1:], columns=vals_main[0])
            for col in ['‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏∏‡∏ô‡∏ï‡πà‡∏≠‡∏´‡∏ô‡πà‡∏ß‡∏¢', '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏ï‡πâ‡∏≠‡∏Å']:
                if col in df_main.columns:
                    df_main[col] = pd.to_numeric(df_main[col].astype(str).str.replace(',', ''), errors='coerce').fillna(0)
        else:
            df_main = pd.DataFrame()

        # AI Memory Data
        try:
            res_mem = sheets_svc.spreadsheets().values().get(spreadsheetId=SPREADSHEET_ID, range="AI_Memory!A:E").execute()
            vals_mem = res_mem.get('values', [])
            
            if vals_mem and len(vals_mem) > 1:
                headers = vals_mem[0]
                rows = vals_mem[1:]
                fixed_rows = [r + [None]*(len(headers)-len(r)) for r in rows]
                df_mem = pd.DataFrame(fixed_rows, columns=headers)
            else:
                df_mem = pd.DataFrame(columns=['SKU', 'AI_Brand', 'AI_Type', 'AI_Spec', 'AI_Tags'])
        except:
            df_mem = pd.DataFrame(columns=['SKU', 'AI_Brand', 'AI_Type', 'AI_Spec', 'AI_Tags'])

        return df_main, df_mem, file_name, last_update

    except Exception as e:
        st.error(f"Load Data Error: {e}")
        return pd.DataFrame(), pd.DataFrame(), "Error", "-"

def append_to_sheet(data_values):
    body = {'values': data_values}
    try:
        sheets_svc.spreadsheets().values().append(
            spreadsheetId=SPREADSHEET_ID, range="AI_Memory!A:A", 
            valueInputOption="USER_ENTERED", body=body
        ).execute()
        return True
    except Exception as e: 
        st.error(f"Save Error: {e}")
        return False

@st.cache_data(ttl=600)
def merge_data(df_main, df_mem):
    if df_mem.empty: return df_main.copy()
    df_main_c = df_main.copy()
    df_mem_c = df_mem.copy()
    df_main_c['‡∏£‡∏´‡∏±‡∏™‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤'] = df_main_c['‡∏£‡∏´‡∏±‡∏™‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤'].astype(str).str.strip()
    df_mem_c['SKU'] = df_mem_c['SKU'].astype(str).str.strip()
    return pd.merge(df_main_c, df_mem_c, left_on='‡∏£‡∏´‡∏±‡∏™‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤', right_on='SKU', how='left')

# Helper Functions
def clean_text(text):
    if not isinstance(text, str): text = str(text)
    return re.sub(r'[^a-zA-Z0-9‡∏Å-‡πô]', '', text).lower()

# ---------------------------------------------------------
# üî• ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô AI (Force JSON + Debug)
# ---------------------------------------------------------
# ‡∏ß‡∏≤‡∏á‡∏ó‡∏±‡∏ö‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô def ask_gemini_extract(names): ‡πÄ‡∏î‡∏¥‡∏°
def ask_gemini_extract(names):
    prompt = f"""
    Analyze product names. Return ONLY JSON Array.
    Input: {json.dumps(names, ensure_ascii=False)}
    Example: [{{"AI_Brand": "Samsung", "AI_Type": "TV", "AI_Spec": "55 Inch", "AI_Tags": "4K"}}]
    If unknown, use "Unknown" or "-".
    """
    try:
        response = ai_model.generate_content(
            prompt,
            generation_config=genai.types.GenerationConfig(response_mime_type="application/json")
        )
        data = json.loads(response.text.strip())
        
        normalized_data = []
        for item in data:
            new_item = {
                "AI_Brand": item.get("AI_Brand") or item.get("Brand") or "Unknown",
                "AI_Type": item.get("AI_Type") or item.get("Type") or "Other",
                "AI_Spec": item.get("AI_Spec") or item.get("Spec") or "-",
                "AI_Tags": item.get("AI_Tags") or item.get("Tags") or ""
            }
            if isinstance(new_item["AI_Tags"], list):
                new_item["AI_Tags"] = ", ".join(new_item["AI_Tags"])
            normalized_data.append(new_item)
            
        return normalized_data
    except: return []

def ask_gemini_filter(query, columns):
    prompt = f"""
    Role: Search Engine. Convert "{query}" to JSON. Cols: {columns}
    
    Rules:
    1. **Primary**: Filter 'AI_Type'/'AI_Brand' if mentioned.
    2. **Range**: "5-8" -> value: ["5", "6", "7", "8"] (Integers only).
    3. **Price Filter**: 
       - If user asks "price?" or "lowest/highest price" WITHOUT specific number -> DO NOT create filter for '‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏∏‡∏ô‡∏ï‡πà‡∏≠‡∏´‡∏ô‡πà‡∏ß‡∏¢'.
       - Create filter ONLY if number exists (e.g. "< 5000").
    4. **Sorting (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç)**:
       - "‡∏ñ‡∏π‡∏Å‡∏™‡∏∏‡∏î", "‡∏ï‡πà‡∏≥‡∏™‡∏∏‡∏î", "‡∏ô‡πâ‡∏≠‡∏¢‡∏™‡∏∏‡∏î" -> sort_order: "asc"
       - "‡πÅ‡∏û‡∏á‡∏™‡∏∏‡∏î", "‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î", "‡∏°‡∏≤‡∏Å‡∏™‡∏∏‡∏î" -> sort_order: "desc"
       - Default -> sort_order: null
    
    Output JSON:
    {{
        "filters": [ {{ "column": "...", "operator": "...", "value": "..." }} ],
        "sort_order": "asc" 
    }}
    """
    try:
        res = ai_model.generate_content(
            prompt, generation_config=genai.types.GenerationConfig(response_mime_type="application/json")
        )
        return json.loads(res.text.strip())
    except: return None
# ---------------------------------------------------------
# 6. MAIN APP UI (TABS)
# ---------------------------------------------------------

# ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
df_main, df_mem, file_name, last_update = load_data_master()

st.title("üí∞ ‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏ä‡πá‡∏Ñ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤ & AI")
st.caption(f"üìÇ ‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {file_name} | üïí ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î: {last_update}")

# ‡∏™‡∏£‡πâ‡∏≤‡∏á TAB ‡πÄ‡∏°‡∏ô‡∏π
tab1, tab2 = st.tabs(["üè† ‡πÄ‡∏ä‡πá‡∏Ñ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏£‡∏≤‡∏¢‡∏ï‡∏±‡∏ß (Code/Name)", "ü§ñ ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞ (AI Search)"])

# =========================================================
# TAB 1: ‡πÄ‡∏ä‡πá‡∏Ñ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏£‡∏≤‡∏¢‡∏ï‡∏±‡∏ß
# =========================================================
with tab1:
    st.info("üí° ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö: ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏£‡∏π‡πâ '‡∏£‡∏´‡∏±‡∏™‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤' ‡∏´‡∏£‡∏∑‡∏≠ '‡∏ä‡∏∑‡πà‡∏≠‡∏£‡∏∏‡πà‡∏ô' ‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡πà‡∏ô‡∏≠‡∏ô")
    
    query1 = st.text_input("‡∏û‡∏¥‡∏°‡∏û‡πå‡∏£‡∏´‡∏±‡∏™‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤ ‡∏´‡∏£‡∏∑‡∏≠ ‡∏ä‡∏∑‡πà‡∏≠‡∏£‡∏∏‡πà‡∏ô", placeholder="‡πÄ‡∏ä‡πà‡∏ô rt20, parsr5lae (‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏™‡πà‡∏Ç‡∏µ‡∏î)", key="search_tab1")
    
    if query1:
        match_index = -1
        found_by = ""
        
        query_clean = clean_text(query1)
        sku_clean_series = df_main['‡∏£‡∏´‡∏±‡∏™‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤'].astype(str).apply(clean_text)
        desc_clean_series = df_main['‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤'].astype(str).apply(clean_text)
        
        sku_matches = df_main[sku_clean_series.str.contains(query_clean, na=False)]
        if not sku_matches.empty:
            match_index = sku_matches.index[0]
            found_by = "‚ö° ‡πÄ‡∏à‡∏≠‡∏£‡∏´‡∏±‡∏™‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤"
        else:
            desc_matches = df_main[desc_clean_series.str.contains(query_clean, na=False)]
            if not desc_matches.empty:
                match_index = desc_matches.index[0]
                found_by = "üîé ‡πÄ‡∏à‡∏≠‡πÉ‡∏ô‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î"
            else:
                keywords = list(filter(None, re.split(r'[^a-zA-Z0-9]', query1)))
                if not keywords: keywords = [query1]
                candidates = df_main[df_main.astype(str).apply(lambda x: any(k.lower() in x.lower() for k in keywords), axis=1)]
                
                if candidates.empty: search_pool = df_main.sample(min(len(df_main), 15))
                else: search_pool = candidates.head(30)
                
                prod_str = search_pool[['‡∏£‡∏´‡∏±‡∏™‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤', '‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤']].to_string(index=True)
                with st.spinner('ü§ñ AI ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ä‡πà‡∏ß‡∏¢‡πÅ‡∏Å‡∏∞‡∏•‡∏≤‡∏¢‡πÅ‡∏ó‡∏á...'):
                    try:
                        res = ai_model.generate_content(f"‡∏´‡∏≤ index ‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö '{query1}' ‡∏à‡∏≤‡∏Å:\n{prod_str}\n‡∏ï‡∏≠‡∏ö‡πÅ‡∏Ñ‡πà‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç index. ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ -1")
                        match_index = int(res.text.strip())
                        found_by = "ü§ñ AI ‡∏Ñ‡πâ‡∏ô‡∏û‡∏ö"
                    except: match_index = -1

        if match_index != -1 and match_index in df_main.index:
            item = df_main.loc[match_index]
            cost = item.get('‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏∏‡∏ô‡∏ï‡πà‡∏≠‡∏´‡∏ô‡πà‡∏ß‡∏¢', 0)
            stock = item.get('‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏ï‡πâ‡∏≠‡∏Å', 0)
            mid = item.get('‡∏£‡∏´‡∏±‡∏™‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤', '-')
            name = item.get('‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤', '-')
            brand = item.get('‡∏¢‡∏µ‡πà‡∏´‡πâ‡∏≠', '-')

            st.success(f"{found_by}: {name}")
            
            target_margin = 12
            sell_price = cost * (1 + (target_margin/100))
            profit = sell_price - cost

            c1, c2, c3 = st.columns([1.3, 1.3, 1])
            with c1:
                st.markdown(f"""<div class="cost-box"><div style="color:#555;font-weight:bold;">üî¥ ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏∏‡∏ô</div><div class="price-value-cost">{cost:,.0f}</div></div>""", unsafe_allow_html=True)
            with c2:
                st.markdown(f"""<div class="selling-box"><div style="color:#555;font-weight:bold;">üü¢ ‡∏Ç‡∏≤‡∏¢‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ (+{target_margin}%)</div><div class="price-value-sell">{sell_price:,.0f}</div><div style="color:#1b5e20;">‡∏Å‡∏≥‡πÑ‡∏£ {profit:,.0f} ‡∏ö‡∏≤‡∏ó</div></div>""", unsafe_allow_html=True)
            with c3:
                st.markdown(f"""<div class="info-box"><b>üÜî ‡∏£‡∏´‡∏±‡∏™:</b> {mid}<br><b>üì¶ ‡∏™‡∏ï‡πâ‡∏≠‡∏Å:</b> {stock}<br><b>üè∑Ô∏è ‡∏¢‡∏µ‡πà‡∏´‡πâ‡∏≠:</b> {brand}</div>""", unsafe_allow_html=True)
                
                st.write("")
                g_q = urllib.parse.quote(name)
                st.link_button("üåê ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏£‡∏π‡∏õ/‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô Google", f"https://www.google.com/search?q={g_q}", use_container_width=True)

            st.divider()
            with st.expander("‡∏î‡∏π‡∏ï‡∏≤‡∏£‡∏≤‡∏á Margin (3% - 30%)", expanded=True):
                margins = [3, 5, 8, 10, 12, 15, 18, 25, 30]
                p_data = [{"‡∏Å‡∏≥‡πÑ‡∏£ %": f"{m}%", "‡∏£‡∏≤‡∏Ñ‡∏≤‡∏Ç‡∏≤‡∏¢": f"{cost*(1+m/100):,.0f}", "‡∏Å‡∏≥‡πÑ‡∏£ (‡∏ö‡∏≤‡∏ó)": f"{(cost*(1+m/100))-cost:,.0f}"} for m in margins]
                st.dataframe(pd.DataFrame(p_data), hide_index=True, use_container_width=True)

            st.divider()
            st.subheader("üõí ‡πÄ‡∏ä‡πá‡∏Ñ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏Ñ‡∏π‡πà‡πÅ‡∏Ç‡πà‡∏á (Hot Search)")
            default_search = re.sub(r'[\u0E00-\u0E7F]', '', str(mid)).strip('-').strip()
            final_kw = st.text_input("üéØ ‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤:", value=default_search, key="hot_kw")
            
            if final_kw:
                enc = urllib.parse.quote(final_kw.strip())
                stores = [
                    {"name": "Shopee", "url": f"https://shopee.co.th/search?keyword={enc}"},
                    {"name": "Lazada", "url": f"https://www.lazada.co.th/catalog/?q={enc}"},
                    {"name": "HomePro", "url": f"https://www.homepro.co.th/search?q={enc}"},
                    {"name": "PowerBuy", "url": f"https://www.powerbuy.co.th/th/search/{enc}"},
                    {"name": "ThaiWatsadu", "url": f"https://www.thaiwatsadu.com/th/search/{enc}"},
                    {"name": "Big C", "url": f"https://www.bigc.co.th/search?q={enc}"},
                    {"name": "Global", "url": f"https://globalhouse.co.th/search?keyword={enc}"},
                    {"name": "Makro", "url": f"https://www.makro.pro/c/search?q={enc}"},
                    {"name": "Dohome", "url": f"https://www.dohome.co.th/search?q={enc}"}
                ]
                
                cols = st.columns(2)
                for i, s in enumerate(stores):
                    with cols[i%2]: st.link_button(f"üîç {s['name']}", s['url'], use_container_width=True)
        else:
            if query1: st.warning(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤: '{query1}'")

# =========================================================
# TAB 2: ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞ AI
# =========================================================
with tab2:
    st.info("üí° ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö: ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏ö‡∏ö‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ ‡πÄ‡∏ä‡πà‡∏ô '‡∏ó‡∏µ‡∏ß‡∏µ Samsung ‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡∏´‡∏°‡∏∑‡πà‡∏ô', '‡πÅ‡∏≠‡∏£‡πå inverter'")
    
    processed_skus = df_mem['SKU'].astype(str).str.strip().tolist() if not df_mem.empty else []
    new_items_df = df_main[~df_main['‡∏£‡∏´‡∏±‡∏™‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤'].astype(str).str.strip().isin(processed_skus)]
    new_count = len(new_items_df)
    
    with st.expander(f"‚öôÔ∏è ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏™‡∏°‡∏≠‡∏á AI ({len(df_mem)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÅ‡∏•‡πâ‡∏ß)"):
        c_a1, c_a2 = st.columns([3, 1])
        c_a1.write(f"‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà AI ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å: **{new_count}** ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
        
        if new_count > 0:
            if c_a2.button("üöÄ ‡∏™‡∏≠‡∏ô AI ‡πÄ‡∏î‡∏µ‡πã‡∏¢‡∏ß‡∏ô‡∏µ‡πâ", type="primary"):
                with st.status("ü§ñ AI ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ...", expanded=True) as status:
                    to_proc = new_items_df[['‡∏£‡∏´‡∏±‡∏™‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤', '‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤']].rename(columns={'‡∏£‡∏´‡∏±‡∏™‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤':'SKU', '‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤':'Name'}).to_dict('records')
                    BATCH = 10
                    res_save = []
                    total_batches = (len(to_proc) // BATCH) + 1
                    
                    for i in range(0, len(to_proc), BATCH):
                        chunk = to_proc[i:i+BATCH]
                        status.write(f"Batch {(i//BATCH)+1}/{total_batches} ({len(chunk)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)...")
                        names = [x['Name'] for x in chunk]
                        ai_res = ask_gemini_extract(names)
                        for idx, item in enumerate(chunk):
                            ar = ai_res[idx] if idx < len(ai_res) else {}
                            res_save.append([item['SKU'], ar.get('AI_Brand','Unknown'), ar.get('AI_Type','Other'), ar.get('AI_Spec','-'), ar.get('AI_Tags','')])
                        time.sleep(4)
                    
                    if res_save:
                        append_to_sheet(res_save)
                        status.update(label="‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!", state="complete")
                        st.balloons()
                        st.cache_data.clear()
                        time.sleep(1)
                        st.rerun()
        else:
            c_a2.button("üîÑ ‡∏£‡∏µ‡πÇ‡∏´‡∏•‡∏î", on_click=lambda: st.cache_data.clear())

    st.divider()
    
    df_search = merge_data(df_main, df_mem)
    
    col_q1, col_q2 = st.columns([4, 1])
    query2 = col_q1.text_input("‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏ö‡∏ö‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥", placeholder="‡πÄ‡∏ä‡πà‡∏ô ‡∏ï‡∏π‡πâ‡πÄ‡∏¢‡πá‡∏ô 2 ‡∏õ‡∏£‡∏∞‡∏ï‡∏π ‡∏£‡∏≤‡∏Ñ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 8000", key="search_tab2")
   # ‡∏ß‡∏≤‡∏á‡∏ï‡πà‡∏≠‡∏à‡∏≤‡∏Å‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î: query2 = col_q1.text_input(...)
if col_q2.button("‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ AI", type="primary"):
        if query2:
            with st.spinner('ü§ñ AI ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡∏¥‡∏î...'):
                cols_ai = ['AI_Brand', 'AI_Type', 'AI_Spec', 'AI_Tags', '‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏∏‡∏ô‡∏ï‡πà‡∏≠‡∏´‡∏ô‡πà‡∏ß‡∏¢']
                result_json = ask_gemini_filter(query2, cols_ai)
                
                if result_json and 'filters' in result_json:
                    filters = result_json['filters']
                    sort_order = result_json.get('sort_order')
                    
                    final_mask = pd.Series([True] * len(df_search))
                    active_conds = []
                    
                    from collections import defaultdict
                    grouped_filters = defaultdict(list)
                    for f in filters:
                        grouped_filters[f['column']].append(f)
                    
                    try:
                        for col, conditions in grouped_filters.items():
                            if col not in df_search.columns: continue
                            
                            col_mask = pd.Series([False] * len(df_search))
                            vals_log = []
                            
                            for f in conditions:
                                op = f['operator']
                                raw_val = f['value']
                                
                                # üî• ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏à‡∏∏‡∏î‡∏ï‡∏≤‡∏¢: ‡∏ñ‡πâ‡∏≤‡∏Ñ‡πà‡∏≤‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô List ‡πÉ‡∏´‡πâ‡πÅ‡∏ï‡∏Å‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡πÄ‡∏ä‡πá‡∏Ñ‡∏ó‡∏µ‡∏•‡∏∞‡∏ï‡∏±‡∏ß
                                # (‡πÄ‡∏ä‡πà‡∏ô ['5', '6', '7'] -> ‡πÄ‡∏ä‡πá‡∏Ñ 5, ‡πÄ‡∏ä‡πá‡∏Ñ 6, ‡πÄ‡∏ä‡πá‡∏Ñ 7)
                                values_list = raw_val if isinstance(raw_val, list) else [raw_val]
                                
                                for val in values_list:
                                    if col == '‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏∏‡∏ô‡∏ï‡πà‡∏≠‡∏´‡∏ô‡πà‡∏ß‡∏¢':
                                        s_val = pd.to_numeric(df_search[col], errors='coerce').fillna(0)
                                        val = float(val)
                                    else:
                                        s_val = df_search[col].astype(str)
                                        val = str(val)
                                    
                                    if op == 'contains': sub_mask = s_val.str.contains(val, case=False, na=False)
                                    elif op == 'equals': sub_mask = (s_val == val)
                                    elif op == 'gt': sub_mask = (s_val > val)
                                    elif op == 'gte': sub_mask = (s_val >= val)
                                    elif op == 'lt': sub_mask = (s_val < val)
                                    elif op == 'lte': sub_mask = (s_val <= val)
                                    else: sub_mask = pd.Series([False] * len(df_search))
                                    
                                    col_mask |= sub_mask # ‡∏£‡∏ß‡∏°‡∏û‡∏•‡∏±‡∏á OR
                                    vals_log.append(f"{val}")
                            
                            final_mask &= col_mask
                            active_conds.append(f"{col}: {', '.join(vals_log)}")
                        
                        results = df_search[final_mask]
                        
                        # Logic ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö
                        if not results.empty and sort_order:
                            if sort_order == 'asc':
                                results = results.sort_values(by='‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏∏‡∏ô‡∏ï‡πà‡∏≠‡∏´‡∏ô‡πà‡∏ß‡∏¢', ascending=True)
                            elif sort_order == 'desc':
                                results = results.sort_values(by='‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏∏‡∏ô‡∏ï‡πà‡∏≠‡∏´‡∏ô‡πà‡∏ß‡∏¢', ascending=False)

                        if not results.empty:
                            st.success(f"‚úÖ ‡∏û‡∏ö {len(results)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
                            st.dataframe(
                                results[['‡∏£‡∏´‡∏±‡∏™‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤', '‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤', '‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏∏‡∏ô‡∏ï‡πà‡∏≠‡∏´‡∏ô‡πà‡∏ß‡∏¢', '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏ï‡πâ‡∏≠‡∏Å', 'AI_Brand', 'AI_Spec']],
                                column_config={
                                    "‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏∏‡∏ô‡∏ï‡πà‡∏≠‡∏´‡∏ô‡πà‡∏ß‡∏¢": st.column_config.NumberColumn("‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏∏‡∏ô", format="‡∏ø%d"), 
                                    "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏ï‡πâ‡∏≠‡∏Å": st.column_config.ProgressColumn("‡∏™‡∏ï‡πâ‡∏≠‡∏Å", format="%d", max_value=int(df_search['‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏ï‡πâ‡∏≠‡∏Å'].max()))
                                },
                                use_container_width=True, hide_index=True
                            )
                        else: 
                            st.warning(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤ (‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç: {'; '.join(active_conds)})")
                            
                    except Exception as e: st.error(f"Error: {e}")
                else:
                    simple = df_search.astype(str).apply(lambda x: x.str.contains(query2, case=False)).any(axis=1)
                    st.dataframe(df_search[simple], use_container_width=True)
