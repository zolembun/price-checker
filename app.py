import streamlit as st
import pandas as pd
import google.generativeai as genai
from google.oauth2.service_account import Credentials
from googleapiclient.discovery import build
import urllib.parse
from datetime import datetime
import re
import json
import time
import streamlit.components.v1 as components

# ---------------------------------------------------------
# 1. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö (‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÅ‡∏£‡∏Å‡∏™‡∏∏‡∏î ‡∏´‡πâ‡∏≤‡∏°‡∏¢‡πâ‡∏≤‡∏¢)
# ---------------------------------------------------------
st.set_page_config(page_title="‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏ä‡πá‡∏Ñ‡∏£‡∏≤‡∏Ñ‡∏≤ & AI", page_icon="üí∞", layout="wide")

# ---------------------------------------------------------
# 2. ‡∏£‡∏∞‡∏ö‡∏ö Login
# ---------------------------------------------------------
def check_password():
    def password_entered():
        if st.session_state["password"] == st.secrets["app_password"]:
            st.session_state["password_correct"] = True
            del st.session_state["password"]
        else:
            st.session_state["password_correct"] = False

    if "password_correct" not in st.session_state:
        st.header("üîí ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏£‡∏∞‡∏ö‡∏ö")
        st.text_input("‡πÉ‡∏™‡πà‡∏£‡∏´‡∏±‡∏™‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô", type="password", on_change=password_entered, key="password")
        return False
    elif not st.session_state["password_correct"]:
        st.header("üîí ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏£‡∏∞‡∏ö‡∏ö")
        st.text_input("‡πÉ‡∏™‡πà‡∏£‡∏´‡∏±‡∏™‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô", type="password", on_change=password_entered, key="password")
        st.error("‚ùå ‡∏£‡∏´‡∏±‡∏™‡∏ú‡πà‡∏≤‡∏ô‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á")
        return False
    else:
        return True

if not check_password():
    st.stop()

# ---------------------------------------------------------
# 3. CSS Styling
# ---------------------------------------------------------
st.markdown("""
<style>
    /* ‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏∏‡∏ô */
    .cost-box { 
        background-color: #ffebee; padding: 15px; border-radius: 10px; 
        border: 2px solid #ef5350; text-align: center; box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    }
    .price-value-cost { font-size: 42px !important; font-weight: 900; color: #c62828; line-height: 1.2;}
    
    /* ‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏£‡∏≤‡∏Ñ‡∏≤‡∏Ç‡∏≤‡∏¢ */
    .selling-box { 
        background-color: #e8f5e9; padding: 15px; border-radius: 10px; 
        border: 2px solid #66bb6a; text-align: center;
    }
    .price-value-sell { font-size: 42px !important; font-weight: 900; color: #2e7d32; line-height: 1.2;}
    
    /* ‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• */
    .info-box {
        background-color: #f8f9fa; padding: 15px; border-radius: 10px; border: 1px solid #ddd;
    }
    
    /* ‡∏õ‡∏∏‡πà‡∏°‡∏Å‡∏î */
    div.stButton > button { width: 100%; border-radius: 8px; font-weight: bold; height: 3em; }
    
    /* ‡∏ã‡πà‡∏≠‡∏ô Header */
    header {visibility: hidden;}
    
    /* Status Widget */
    .stStatusWidget { border-radius: 10px; }
    .stock-box { 
        background-color: #e3f2fd; padding: 15px; border-radius: 10px; 
        border: 2px solid #2196f3; text-align: center; box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    }
    .price-value-stock { font-size: 42px !important; font-weight: 900; color: #1565c0; line-height: 1.2;}

    /* ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Å‡∏•‡πà‡∏≠‡∏á Info ‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡∏Ç‡∏∂‡πâ‡∏ô */
    .detail-bar {
        margin-top: 10px; padding: 10px; background-color: #f1f3f4; 
        border-radius: 8px; text-align: center; font-size: 14px; color: #333;
    }
</style>
""", unsafe_allow_html=True)

# ---------------------------------------------------------
# 4. ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Services
# ---------------------------------------------------------
@st.cache_resource
def init_services():
    try:
        service_account_info = st.secrets["gcp_service_account"]
        gemini_key = st.secrets["gemini_api_key"]
        
        scopes = ['https://www.googleapis.com/auth/spreadsheets', 
                  'https://www.googleapis.com/auth/drive.metadata.readonly']
        creds = Credentials.from_service_account_info(service_account_info, scopes=scopes)
        
        sheets_service = build('sheets', 'v4', credentials=creds)
        drive_service = build('drive', 'v3', credentials=creds)
        
        # Config Gemini
        genai.configure(api_key=gemini_key)
        
        # üî• ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà Error: ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏∏‡πà‡∏ô Latest
        try:
            model = genai.GenerativeModel('gemini-2.0-flash')
        except:
            # Fallback ‡∏ñ‡πâ‡∏≤ latest ‡πÉ‡∏ä‡πâ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‡πÉ‡∏´‡πâ‡∏•‡∏≠‡∏á‡∏ï‡∏±‡∏ß‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤‡∏´‡∏£‡∏∑‡∏≠ Pro
            model = genai.GenerativeModel('gemini-2.5-flash')
        
        return sheets_service, drive_service, model
    except Exception as e:
        st.error(f"Config Error: {e}")
        return None, None, None

sheets_svc, drive_svc, ai_model = init_services()
if not sheets_svc: st.stop()

try:
    SHEET_URL = st.secrets["sheet_url"]
    SPREADSHEET_ID = SHEET_URL.split('/d/')[1].split('/')[0]
except:
    st.error("‡πÑ‡∏°‡πà‡∏û‡∏ö sheet_url ‡πÉ‡∏ô Secrets")
    st.stop()

# ---------------------------------------------------------
# 5. ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÇ‡∏´‡∏•‡∏î/‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
# ---------------------------------------------------------
@st.cache_data(ttl=600)
def load_data_master():
    try:
        # Metadata
        file_meta = drive_svc.files().get(fileId=SPREADSHEET_ID, fields="name, modifiedTime").execute()
        file_name = file_meta.get('name')
        dt = datetime.strptime(file_meta.get('modifiedTime'), "%Y-%m-%dT%H:%M:%S.%fZ")
        last_update = dt.strftime("%d/%m/%Y %H:%M ‡∏ô.")

        # Main Data
        res_main = sheets_svc.spreadsheets().values().get(spreadsheetId=SPREADSHEET_ID, range="A:H").execute()
        vals_main = res_main.get('values', [])
        
        if vals_main:
            df_main = pd.DataFrame(vals_main[1:], columns=vals_main[0])
            for col in ['‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏∏‡∏ô‡∏ï‡πà‡∏≠‡∏´‡∏ô‡πà‡∏ß‡∏¢', '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏ï‡πâ‡∏≠‡∏Å']:
                if col in df_main.columns:
                    df_main[col] = pd.to_numeric(df_main[col].astype(str).str.replace(',', ''), errors='coerce').fillna(0)
        else:
            df_main = pd.DataFrame()

        # AI Memory Data
        try:
            # üî• ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà 1: ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ñ‡∏∂‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå F (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÑ‡∏î‡πâ AI_Kind)
            res_mem = sheets_svc.spreadsheets().values().get(spreadsheetId=SPREADSHEET_ID, range="AI_Memory!A:F").execute()
            vals_mem = res_mem.get('values', [])
            
            # üî• ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà 2: ‡πÄ‡∏û‡∏¥‡πà‡∏° AI_Kind ‡πÉ‡∏ô‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
            cols_mem = ['SKU', 'AI_Brand', 'AI_Type', 'AI_Spec', 'AI_Tags', 'AI_Kind']

            if vals_mem and len(vals_mem) > 1:
                headers = vals_mem[0]
                rows = vals_mem[1:]
                # ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡πà‡∏≤‡∏ß‡πà‡∏≤‡∏á‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏ö‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ñ‡πâ‡∏≤‡∏°‡∏±‡∏ô‡πÅ‡∏´‡∏ß‡πà‡∏á
                fixed_rows = [r + [None]*(len(headers)-len(r)) for r in rows]
                df_mem = pd.DataFrame(fixed_rows, columns=headers)
                
                # ‡∏ñ‡πâ‡∏≤‡πÇ‡∏´‡∏•‡∏î‡∏°‡∏≤‡πÅ‡∏•‡πâ‡∏ß‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå AI_Kind ‡πÉ‡∏´‡πâ‡πÄ‡∏ï‡∏¥‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ
                if 'AI_Kind' not in df_mem.columns:
                    df_mem['AI_Kind'] = ''
            else:
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤‡πÅ‡∏ö‡∏ö‡∏°‡∏µ AI_Kind ‡∏£‡∏≠‡πÑ‡∏ß‡πâ
                df_mem = pd.DataFrame(columns=cols_mem)
        except Exception as e:
            # ‡∏Å‡∏£‡∏ì‡∏µ Error ‡∏Å‡πá‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏µ AI_Kind ‡πÑ‡∏ß‡πâ‡∏Å‡πà‡∏≠‡∏ô
            print(f"Load Mem Error: {e}")
            df_mem = pd.DataFrame(columns=['SKU', 'AI_Brand', 'AI_Type', 'AI_Spec', 'AI_Tags', 'AI_Kind'])

        return df_main, df_mem, file_name, last_update

    except Exception as e:
        st.error(f"Load Data Error: {e}")
        return pd.DataFrame(), pd.DataFrame(), "Error", "-"

def append_to_sheet(data_values):
    body = {'values': data_values}
    try:
        sheets_svc.spreadsheets().values().append(
            spreadsheetId=SPREADSHEET_ID, range="AI_Memory!A:A", 
            valueInputOption="USER_ENTERED", body=body
        ).execute()
        return True
    except Exception as e: 
        st.error(f"Save Error: {e}")
        return False

def overwrite_memory_sheet(df_new_mem):
    try:
        # 1. ‡πÅ‡∏õ‡∏•‡∏á DataFrame ‡πÄ‡∏õ‡πá‡∏ô List ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å
        # ‡∏ï‡πâ‡∏≠‡∏á‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ NaN ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô empty string ‡πÑ‡∏°‡πà‡∏á‡∏±‡πâ‡∏ô Error
        df_new_mem = df_new_mem.fillna('') 
        values = [df_new_mem.columns.tolist()] + df_new_mem.values.tolist()
        
        # 2. ‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô AI_Memory
        sheets_svc.spreadsheets().values().clear(
            spreadsheetId=SPREADSHEET_ID, range="AI_Memory!A:E"
        ).execute()

        # 3. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà‡∏•‡∏á‡πÑ‡∏õ
        body = {'values': values}
        sheets_svc.spreadsheets().values().update(
            spreadsheetId=SPREADSHEET_ID, range="AI_Memory!A1",
            valueInputOption="USER_ENTERED", body=body
        ).execute()
        return True
    except Exception as e:
        st.error(f"Cleanup Error: {e}")
        return False

@st.cache_data(ttl=600)
def merge_data(df_main, df_mem):
    # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• AI ‡πÉ‡∏´‡πâ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏î‡∏¥‡∏°‡πÑ‡∏õ‡∏Å‡πà‡∏≠‡∏ô
    if df_mem.empty: return df_main.copy()
    
    # Copy ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏´‡∏•‡∏±‡∏Å
    df_main_c = df_main.copy()
    df_mem_c = df_mem.copy()
    
    # üî• ‡∏à‡∏∏‡∏î‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç 1: ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠ + ‡∏ï‡∏±‡∏ß‡∏û‡∏¥‡∏°‡∏û‡πå‡πÉ‡∏´‡∏ç‡πà + ‡∏ï‡∏±‡∏î‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á (Normalize)
    # ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ "sku01" ‡πÑ‡∏°‡πà‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ö "SKU01" ‡∏´‡∏£‡∏∑‡∏≠ " SKU01 "
    df_main_c['join_key'] = df_main_c['‡∏£‡∏´‡∏±‡∏™‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤'].astype(str).str.strip().str.upper()
    df_mem_c['join_key'] = df_mem_c['SKU'].astype(str).str.strip().str.upper()
    
    # 2. ‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà (Merge) ‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏û‡∏¥‡πÄ‡∏®‡∏©‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô (join_key)
    merged = pd.merge(df_main_c, df_mem_c, on='join_key', how='left')
    
    # 3. ‡∏ñ‡∏°‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å: ‡∏ñ‡πâ‡∏≤ AI ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å ‡πÉ‡∏´‡πâ‡πÉ‡∏™‡πà‡∏Ñ‡πà‡∏≤‡∏ß‡πà‡∏≤‡∏á ‡∏≠‡∏¢‡πà‡∏≤‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô NaN)
    cols_to_fix = ['AI_Brand', 'AI_Type', 'AI_Spec', 'AI_Tags', 'AI_Kind'] 
    for col in cols_to_fix:
        if col in merged.columns:
            # fillna('') ‡∏à‡∏∞‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Ñ‡πà‡∏≤‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô string ‡∏ß‡πà‡∏≤‡∏á‡πÜ ‡πÑ‡∏°‡πà error ‡πÄ‡∏ß‡∏•‡∏≤‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤
            merged[col] = merged[col].fillna('').astype(str)
    
    # ‡∏•‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ä‡πà‡∏ß‡∏¢ (join_key) ‡∏ó‡∏¥‡πâ‡∏á
    if 'join_key' in merged.columns:
        del merged['join_key']
            
    return merged
# ---------------------------------------------------------
# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÅ‡∏Å‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤ (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏∏‡πà‡∏° "‡∏™‡∏≠‡∏ô AI")
# ---------------------------------------------------------
# ---------------------------------------------------------
# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÅ‡∏Å‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤ (‡∏â‡∏ö‡∏±‡∏ö‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£: Retry 3 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á + ‡∏û‡∏±‡∏Å‡∏ô‡∏≤‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô)
# ---------------------------------------------------------
def ask_gemini_extract(names):
    # ‡∏Ñ‡πà‡∏≤ Default ‡∏Å‡∏£‡∏ì‡∏µ‡∏û‡∏±‡∏á‡∏à‡∏£‡∏¥‡∏á‡πÜ
    default_list = []
    for _ in names:
        default_list.append({
            "AI_Brand": "Unknown", "AI_Type": "Other", 
            "AI_Kind": "", "AI_Spec": "-", "AI_Tags": ""
        })

    if not names: return []

    prompt = f"""
    Extract product info from this list:
    {json.dumps(names, ensure_ascii=False)}

    Return JSON Array with these keys:
    - AI_Brand (Use Uppercase e.g. SAMSUNG)
    - AI_Type (Category in Thai e.g. ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ã‡∏±‡∏Å‡∏ú‡πâ‡∏≤, ‡∏ó‡∏µ‡∏ß‡∏µ)
    - AI_Kind (Sub-type in Thai e.g. ‡∏ù‡∏≤‡∏ö‡∏ô, 2 ‡∏ñ‡∏±‡∏á. If unknown use "")
    - AI_Spec (Capacity/Size e.g. 10 kg, 55 ‡∏ô‡∏¥‡πâ‡∏ß)
    - AI_Tags (Features e.g. inverter, smart tv)

    Response Format: JSON Array ONLY. No Markdown.
    """
    
    # üî• ‡∏£‡∏∞‡∏ö‡∏ö‡∏ï‡∏∑‡πâ‡∏≠ 3 ‡∏£‡∏≠‡∏ö (Retry Logic) üî•
    max_retries = 3
    for attempt in range(max_retries):
        try:
            # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å AI
            response = ai_model.generate_content(
                prompt,
                generation_config=genai.types.GenerationConfig(
                    response_mime_type="application/json"
                )
            )
            
            txt = response.text.strip()
            # ‡∏•‡πâ‡∏≤‡∏á Markdown
            txt_clean = re.sub(r"```json|```", "", txt).strip()
            
            data = json.loads(txt_clean)

            # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
            normalized_data = []
            for item in data:
                new_item = {
                    "AI_Brand": item.get("AI_Brand") or "Unknown",
                    "AI_Type": item.get("AI_Type") or "Other",
                    "AI_Kind": item.get("AI_Kind") or "", 
                    "AI_Spec": item.get("AI_Spec") or "-",
                    "AI_Tags": item.get("AI_Tags") or ""
                }
                if isinstance(new_item["AI_Tags"], list):
                    new_item["AI_Tags"] = ", ".join(new_item["AI_Tags"])
                normalized_data.append(new_item)
            
            # ‡∏ñ‡πâ‡∏≤‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡∏Ñ‡∏£‡∏ö (‡πÄ‡∏ä‡πà‡∏ô‡∏™‡πà‡∏á‡πÑ‡∏õ 10 ‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤ 5) ‡πÉ‡∏´‡πâ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤ Error ‡πÅ‡∏•‡πâ‡∏ß‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà
            if len(normalized_data) != len(names):
                print(f"‚ö†Ô∏è ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÑ‡∏°‡πà‡∏Ñ‡∏£‡∏ö ({len(normalized_data)}/{len(names)}) ‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà...")
                raise ValueError("Data mismatch")
                
            return normalized_data # ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! ‡∏™‡πà‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏•‡∏¢

        except Exception as e:
            # ‡∏™‡∏π‡∏ï‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏ß‡∏•‡∏≤‡∏£‡∏≠: ‡∏£‡∏≠‡∏ö 1=5‡∏ß‡∏¥, ‡∏£‡∏≠‡∏ö 2=10‡∏ß‡∏¥, ‡∏£‡∏≠‡∏ö 3=15‡∏ß‡∏¥
            wait_time = (attempt + 1) * 5 
            print(f"‚ö†Ô∏è AI Error (‡∏£‡∏≠‡∏ö {attempt+1}): {e} ... ‡∏£‡∏≠ {wait_time} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ")
            time.sleep(wait_time)
    
    # ‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏£‡∏ö 3 ‡∏£‡∏≠‡∏ö‡πÅ‡∏•‡πâ‡∏ß‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏à‡∏£‡∏¥‡∏á‡πÜ ‡∏Ñ‡πà‡∏≠‡∏¢‡∏¢‡∏≠‡∏°‡πÅ‡∏û‡πâ
    return default_list
# ---------------------------------------------------------
# üî• ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô AI (‡πÇ‡∏´‡∏°‡∏î DEBUG: ‡πÅ‡∏™‡∏î‡∏á Error ‡πÉ‡∏´‡πâ‡πÄ‡∏´‡πá‡∏ô‡∏à‡∏∞‡πÜ)
# ---------------------------------------------------------
def ask_gemini_filter(query, columns, df_lookup=None):
    # ---------------------------------------------------------
    # PART 1: ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° Context (‡∏™‡πà‡∏á‡πÇ‡∏û‡∏¢ Top 50 ‡πÉ‡∏´‡πâ AI ‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡πÉ‡∏ô‡∏£‡πâ‡∏≤‡∏ô)
    # ---------------------------------------------------------
    context_str = ""
    if df_lookup is not None:
        try:
            # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡∏¥‡∏¢‡∏° (Most Popular)
            brands = df_lookup['AI_Brand'].value_counts().index.tolist()
            types = df_lookup['AI_Type'].value_counts().index.tolist()
            kinds = df_lookup['AI_Kind'].value_counts().index.tolist()
            
            # Limit Token: ‡∏™‡πà‡∏á‡πÑ‡∏õ‡πÅ‡∏Ñ‡πà‡∏ï‡∏±‡∏ß‡∏ó‡πá‡∏≠‡∏õ‡πÜ
            brand_list = json.dumps(brands[:60], ensure_ascii=False)
            type_list = json.dumps(types[:40], ensure_ascii=False)
            kind_list = json.dumps(kinds[:60], ensure_ascii=False)
            
            context_str = f"""
            [Database Context - Use these exact values for mapping]
            - Known Brands: {brand_list}
            - Known Types: {type_list}
            - Known Kinds: {kind_list}
            """
        except: pass

    # ---------------------------------------------------------
    # PART 2: Prompt ‡∏™‡∏±‡πà‡∏á‡∏á‡∏≤‡∏ô (‡∏ú‡∏™‡∏≤‡∏ô‡∏Å‡∏é‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ó‡∏®‡∏ô‡∏¥‡∏¢‡∏°‡πÅ‡∏•‡∏∞‡∏ä‡πà‡∏ß‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç)
    # ---------------------------------------------------------
    prompt = f"""
    Role: ‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ Search Engine ‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞ ‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ "{query}" ‡πÄ‡∏õ‡πá‡∏ô JSON Filter
    Target Columns: {columns}
    
    {context_str}

    Instruction (Strict Rules):
    1. **Context Mapping (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î)**: 
       - ‡∏Å‡πà‡∏≠‡∏ô‡∏à‡∏∞‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à ‡πÉ‡∏´‡πâ‡∏î‡∏π‡πÉ‡∏ô [Database Context] ‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô‡∏Å‡πà‡∏≠‡∏ô
       - ‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö Known Brands/Types ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏ô‡∏±‡πâ‡∏ô‡πÄ‡∏õ‡πä‡∏∞‡πÜ (‡πÄ‡∏ä‡πà‡∏ô User ‡∏û‡∏¥‡∏°‡∏û‡πå "Mitsu" -> ‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ‡πÄ‡∏õ‡πá‡∏ô "MITSUBISHI" ‡∏ï‡∏≤‡∏°‡πÉ‡∏ô‡∏•‡∏¥‡∏™‡∏ï‡πå)
       - **Thai Splitting Rule (‡πÄ‡∏û‡∏¥‡πà‡∏°)**: ‡∏ñ‡πâ‡∏≤‡πÄ‡∏à‡∏≠‡∏ä‡∏∑‡πà‡∏≠‡πÅ‡∏ö‡∏£‡∏ô‡∏î‡πå‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏´‡∏•‡∏≤‡∏¢‡∏Ñ‡∏≥‡πÄ‡∏ß‡πâ‡∏ô‡∏ß‡∏£‡∏£‡∏Ñ (‡πÄ‡∏ä‡πà‡∏ô "‡πÑ‡∏Æ‡πÄ‡∏≠‡∏≠‡∏£‡πå ‡πÅ‡∏≠‡∏•‡∏à‡∏µ") **‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏¢‡∏Å (SPLIT)** ‡πÄ‡∏õ‡πá‡∏ô Filter ‡∏´‡∏•‡∏≤‡∏¢‡∏ï‡∏±‡∏ß
         * ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: "‡πÑ‡∏Æ‡πÄ‡∏≠‡∏≠‡∏£‡πå ‡πÅ‡∏≠‡∏•‡∏à‡∏µ" -> ‡πÉ‡∏´‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á 2 filters:
           {{ "column": "AI_Brand", "operator": "contains", "value": "HAIER" }},
           {{ "column": "AI_Brand", "operator": "contains", "value": "LG" }}

    2. **Price & Spec Logic**: 
       - ‡∏ñ‡πâ‡∏≤‡πÄ‡∏à‡∏≠‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏£‡∏≤‡∏Ñ‡∏≤ ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ 'lte' (‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô) ‡∏´‡∏£‡∏∑‡∏≠ 'gte' (‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà)
       - ‡∏´‡πâ‡∏≤‡∏°‡πÉ‡∏ä‡πâ 'contains' ‡∏Å‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏£‡∏≤‡∏Ñ‡∏≤

    3. **Decimal Range Strategy (Spec Only)**: 
       - ‡∏ñ‡πâ‡∏≤ User ‡∏£‡∏∞‡∏ö‡∏∏‡∏ä‡πà‡∏ß‡∏á‡∏Ç‡∏ô‡∏≤‡∏î/‡∏™‡πÄ‡∏õ‡∏Ñ (‡πÄ‡∏ä‡πà‡∏ô "5.5 - 6 ‡∏Ñ‡∏¥‡∏ß", "9000-12000 btu") 
       - **‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ operator 'gte' (>=) ‡πÅ‡∏•‡∏∞ 'lte' (<=) ‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå AI_Spec**
       - ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: "5.5 - 6 ‡∏Ñ‡∏¥‡∏ß" -> 
         {{ "column": "AI_Spec", "operator": "gte", "value": "5.5" }},
         {{ "column": "AI_Spec", "operator": "lte", "value": "6.0" }}
       - ‡∏´‡πâ‡∏≤‡∏°‡πÉ‡∏ä‡πâ 'contains' ‡∏´‡∏£‡∏∑‡∏≠ 'in' ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ä‡πà‡∏ß‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏™‡πÄ‡∏õ‡∏Ñ

    4. **Single Number Spec**: 
       - ‡∏ñ‡πâ‡∏≤‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏•‡∏Ç‡πÄ‡∏î‡∏µ‡∏¢‡∏ß (‡πÄ‡∏ä‡πà‡∏ô "5 ‡∏Ñ‡∏¥‡∏ß") ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ 'contains' ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°
       - ‡πÅ‡∏ï‡πà‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏®‡∏ô‡∏¥‡∏¢‡∏° (‡πÄ‡∏ä‡πà‡∏ô "10.5 kg") ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ 'contains' ‡∏´‡∏£‡∏∑‡∏≠ 'eq' ‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏‡∏Ñ‡πà‡∏≤ "10.5" ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô

    Output Format (JSON ONLY):
    {{
        "filters": [ ... ],
        "sort_order": "asc"
    }}
    """
    
    try:
        res = ai_model.generate_content(prompt, generation_config=genai.types.GenerationConfig(response_mime_type="application/json"))
        return json.loads(res.text.strip())
    except: return None
def clean_text(text):
    # üëá ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏ß‡πâ‡∏ô‡∏ß‡∏£‡∏£‡∏Ñ (Indentation) ‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ
    if not text: return ""
    return re.sub(r'[^a-zA-Z0-9]', '', str(text)).lower()
# ---------------------------------------------------------
# 6. MAIN APP UI (TABS)
# ---------------------------------------------------------

# ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
df_main, df_mem, file_name, last_update = load_data_master()

st.title("üí∞ ‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏ä‡πá‡∏Ñ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤ & AI")
st.caption(f"üìÇ ‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {file_name} | üïí ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î: {last_update}")

# ‡∏™‡∏£‡πâ‡∏≤‡∏á TAB ‡πÄ‡∏°‡∏ô‡∏π
tab1, tab2 = st.tabs(["üè† ‡πÄ‡∏ä‡πá‡∏Ñ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏£‡∏≤‡∏¢‡∏ï‡∏±‡∏ß (Code/Name)", "ü§ñ ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞ (AI Search)"])

# =========================================================
# TAB 1: ‡πÄ‡∏ä‡πá‡∏Ñ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏£‡∏≤‡∏¢‡∏ï‡∏±‡∏ß
# =========================================================
with tab1:
    st.info("üí° ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö: ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏£‡∏π‡πâ '‡∏£‡∏´‡∏±‡∏™‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤' ‡∏´‡∏£‡∏∑‡∏≠ '‡∏ä‡∏∑‡πà‡∏≠‡∏£‡∏∏‡πà‡∏ô' ‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡πà‡∏ô‡∏≠‡∏ô")
    
    query1 = st.text_input("‡∏û‡∏¥‡∏°‡∏û‡πå‡∏£‡∏´‡∏±‡∏™‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤ ‡∏´‡∏£‡∏∑‡∏≠ ‡∏ä‡∏∑‡πà‡∏≠‡∏£‡∏∏‡πà‡∏ô", placeholder="‡πÄ‡∏ä‡πà‡∏ô rt20, parsr5lae (‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏™‡πà‡∏Ç‡∏µ‡∏î)", key="search_tab1")
    
    if query1:
        match_index = -1
        found_by = ""
        
        query_clean = clean_text(query1)
        sku_clean_series = df_main['‡∏£‡∏´‡∏±‡∏™‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤'].astype(str).apply(clean_text)
        desc_clean_series = df_main['‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤'].astype(str).apply(clean_text)
        
        sku_matches = df_main[sku_clean_series.str.contains(query_clean, na=False)]
        if not sku_matches.empty:
            match_index = sku_matches.index[0]
            found_by = "‚ö° ‡πÄ‡∏à‡∏≠‡∏£‡∏´‡∏±‡∏™‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤"
        else:
            desc_matches = df_main[desc_clean_series.str.contains(query_clean, na=False)]
            if not desc_matches.empty:
                match_index = desc_matches.index[0]
                found_by = "üîé ‡πÄ‡∏à‡∏≠‡πÉ‡∏ô‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î"
            else:
                keywords = list(filter(None, re.split(r'[^a-zA-Z0-9]', query1)))
                if not keywords: keywords = [query1]
                # ‡πÅ‡∏Å‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ô‡∏µ‡πâ‡∏Ñ‡∏£‡∏±‡∏ö
                candidates = df_main[df_main.astype(str).apply(lambda x: any(k.lower() in ' '.join(x).lower() for k in keywords), axis=1)]
                
                if candidates.empty: search_pool = df_main.sample(min(len(df_main), 15))
                else: search_pool = candidates.head(30)
                
                prod_str = search_pool[['‡∏£‡∏´‡∏±‡∏™‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤', '‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤']].to_string(index=True)
                with st.spinner('ü§ñ AI ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ä‡πà‡∏ß‡∏¢‡πÅ‡∏Å‡∏∞‡∏•‡∏≤‡∏¢‡πÅ‡∏ó‡∏á...'):
                    try:
                        res = ai_model.generate_content(f"‡∏´‡∏≤ index ‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö '{query1}' ‡∏à‡∏≤‡∏Å:\n{prod_str}\n‡∏ï‡∏≠‡∏ö‡πÅ‡∏Ñ‡πà‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç index. ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ -1")
                        match_index = int(res.text.strip())
                        found_by = "ü§ñ AI ‡∏Ñ‡πâ‡∏ô‡∏û‡∏ö"
                    except: match_index = -1

        if match_index != -1 and match_index in df_main.index:
            item = df_main.loc[match_index]
            cost = item.get('‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏∏‡∏ô‡∏ï‡πà‡∏≠‡∏´‡∏ô‡πà‡∏ß‡∏¢', 0)
            stock = item.get('‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏ï‡πâ‡∏≠‡∏Å', 0)
            mid = item.get('‡∏£‡∏´‡∏±‡∏™‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤', '-')
            name = item.get('‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤', '-')
            brand = item.get('‡∏¢‡∏µ‡πà‡∏´‡πâ‡∏≠', '-')

            st.success(f"{found_by}: {name}")
            
            target_margin = 12
            sell_price = cost * (1 + (target_margin/100))
            profit = sell_price - cost

            # -------------------------------------------------------
            # ‚ú® [‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÉ‡∏´‡∏°‡πà] ‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô 3 ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ô (‡∏ó‡∏∏‡∏ô | ‡∏Ç‡∏≤‡∏¢ | ‡∏™‡∏ï‡πâ‡∏≠‡∏Å)
            # -------------------------------------------------------
            c1, c2, c3 = st.columns([1, 1, 1]) 
            
            with c1:
                st.markdown(f"""
                <div class="cost-box">
                    <div style="color:#555;font-weight:bold;">üî¥ ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏∏‡∏ô</div>
                    <div class="price-value-cost">{cost:,.0f}</div>
                </div>
                """, unsafe_allow_html=True)

            with c2:
                st.markdown(f"""
                <div class="selling-box">
                    <div style="color:#555;font-weight:bold;">üü¢ ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏Ç‡∏≤‡∏¢ (+{target_margin}%)</div>
                    <div class="price-value-sell">{sell_price:,.0f}</div>
                    <div style="font-size:12px; color:#2e7d32;">(‡∏Å‡∏≥‡πÑ‡∏£ {profit:,.0f} ‡∏ö.)</div>
                </div>
                """, unsafe_allow_html=True)
                
            with c3:
                # ‡∏ï‡∏Å‡πÅ‡∏ï‡πà‡∏á: ‡∏ñ‡πâ‡∏≤‡∏™‡∏ï‡πâ‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô 0 ‡πÉ‡∏´‡πâ‡πÄ‡∏•‡∏Ç‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏µ‡πÅ‡∏î‡∏á, ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ç‡∏≠‡∏á‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏µ‡∏ü‡πâ‡∏≤
                stock_color = "#c62828" if stock == 0 else "#1565c0"
                st.markdown(f"""
                <div class="stock-box">
                    <div style="color:#555;font-weight:bold;">üì¶ ‡∏™‡∏ï‡πâ‡∏≠‡∏Å‡∏Ñ‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠</div>
                    <div class="price-value-stock" style="color: {stock_color};">{stock:,.0f}</div>
                    <div style="font-size:12px; color:#555;">‡∏´‡∏ô‡πà‡∏ß‡∏¢</div>
                </div>
                """, unsafe_allow_html=True)

           # ... (‡πÇ‡∏Ñ‡πâ‡∏î‡∏™‡πà‡∏ß‡∏ô‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏•‡πà‡∏≠‡∏á 3 ‡∏Å‡∏•‡πà‡∏≠‡∏á: ‡∏ó‡∏∏‡∏ô/‡∏Ç‡∏≤‡∏¢/‡∏™‡∏ï‡πâ‡∏≠‡∏Å ‡∏≠‡∏¢‡∏π‡πà‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°) ...

            # -------------------------------------------------------
            # ‚ú® [‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç] 1. ‡πÅ‡∏ñ‡∏ö‡πÇ‡∏ä‡∏ß‡πå‡∏£‡∏´‡∏±‡∏™‡πÅ‡∏•‡∏∞‡∏¢‡∏µ‡πà‡∏´‡πâ‡∏≠ (‡πÄ‡∏≠‡∏≤‡∏•‡∏¥‡∏á‡∏Å‡πå Google ‡∏≠‡∏≠‡∏Å‡πÑ‡∏õ‡πÅ‡∏•‡πâ‡∏ß)
            # -------------------------------------------------------
            st.markdown(f"""
            <div class="detail-bar">
                <b>üÜî ‡∏£‡∏´‡∏±‡∏™:</b> {mid} &nbsp;&nbsp;|&nbsp;&nbsp; 
                <b>üè∑Ô∏è ‡∏¢‡∏µ‡πà‡∏´‡πâ‡∏≠:</b> {brand}
            </div>
            """, unsafe_allow_html=True)

            # -------------------------------------------------------
            # ‚ú® [‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÉ‡∏´‡∏°‡πà] 2. ‡∏õ‡∏∏‡πà‡∏°‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ Google ‡πÅ‡∏¢‡∏Å‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡∏ï‡πà‡∏≤‡∏á‡∏´‡∏≤‡∏Å (‡∏Å‡∏î‡∏á‡πà‡∏≤‡∏¢‡∏Ç‡∏∂‡πâ‡∏ô)
            # -------------------------------------------------------
            st.write("") # ‡πÄ‡∏ß‡πâ‡∏ô‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á‡∏ô‡∏¥‡∏î‡∏ô‡∏∂‡∏á
            google_q = urllib.parse.quote(name)
            st.link_button(
                "üåê ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏£‡∏π‡∏õ/‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡πÉ‡∏ô Google", 
                f"https://www.google.com/search?q={google_q}", 
                use_container_width=True  # ‡πÉ‡∏´‡πâ‡∏õ‡∏∏‡πà‡∏°‡∏Å‡∏ß‡πâ‡∏≤‡∏á‡πÄ‡∏ï‡πá‡∏°‡∏à‡∏≠
            )
            
            # ... (‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏™‡πâ‡∏ô‡∏Å‡∏±‡πâ‡∏ô st.divider() ‡πÅ‡∏•‡∏∞‡∏ï‡∏≤‡∏£‡∏≤‡∏á Margin ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°) ...

            st.divider()
            with st.expander("‡∏î‡∏π‡∏ï‡∏≤‡∏£‡∏≤‡∏á Margin (3% - 30%)", expanded=True):
                margins = [3, 5, 8, 10, 12, 15, 18, 25, 30]
                p_data = [{"‡∏Å‡∏≥‡πÑ‡∏£ %": f"{m}%", "‡∏£‡∏≤‡∏Ñ‡∏≤‡∏Ç‡∏≤‡∏¢": f"{cost*(1+m/100):,.0f}", "‡∏Å‡∏≥‡πÑ‡∏£ (‡∏ö‡∏≤‡∏ó)": f"{(cost*(1+m/100))-cost:,.0f}"} for m in margins]
                st.dataframe(pd.DataFrame(p_data), hide_index=True, use_container_width=True)

            st.divider()
            st.subheader("üõí ‡πÄ‡∏ä‡πá‡∏Ñ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏Ñ‡∏π‡πà‡πÅ‡∏Ç‡πà‡∏á (Hot Search)")
            default_search = re.sub(r'[\u0E00-\u0E7F]', '', str(mid)).strip('-').strip()
            final_kw = st.text_input("üéØ ‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤:", value=default_search, key=f"hot_kw_{match_index}")
            
            if final_kw:
                enc = urllib.parse.quote(final_kw.strip())
                stores = [
                    {"name": "Shopee", "url": f"https://shopee.co.th/search?keyword={enc}"},
                    {"name": "Lazada", "url": f"https://www.lazada.co.th/catalog/?q={enc}"},
                    {"name": "HomePro", "url": f"https://www.homepro.co.th/search?q={enc}"},
                    {"name": "PowerBuy", "url": f"https://www.powerbuy.co.th/th/search/{enc}"},
                    {"name": "ThaiWatsadu", "url": f"https://www.thaiwatsadu.com/th/search/{enc}"},
                    {"name": "Big C", "url": f"https://www.bigc.co.th/search?q={enc}"},
                    {"name": "Global", "url": f"https://globalhouse.co.th/search?keyword={enc}"},
                    {"name": "Makro", "url": f"https://www.makro.pro/c/search?q={enc}"},
                    {"name": "Dohome", "url": f"https://www.dohome.co.th/search?q={enc}"}
                ]
               # ... (‡πÇ‡∏Ñ‡πâ‡∏î‡∏™‡πà‡∏ß‡∏ô stores = [...] ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°) ...

            # -------------------------------------------------------
            # ‚úÖ ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÉ‡∏´‡∏°‡πà: ‡πÉ‡∏ä‡πâ components.html ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á Error ‡∏Ç‡∏≠‡∏á React
            # -------------------------------------------------------
            
            # 1. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° Script ‡πÄ‡∏õ‡∏¥‡∏î‡∏•‡∏¥‡πâ‡∏á‡∏Ñ‡πå
            js_items = [f"window.open('{s['url']}', '_blank');" for s in stores]
            js_command = "".join(js_items)

            # 2. ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô HTML + CSS + JS ‡∏£‡∏ß‡∏°‡∏Å‡∏±‡∏ô‡πÉ‡∏ô‡∏Å‡πâ‡∏≠‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
            html_button = f"""
            <!DOCTYPE html>
            <html>
            <head>
            <style>
                body {{ margin: 0; padding: 0; font-family: sans-serif; }}
                .mobile-launch-btn {{
                    background: linear-gradient(90deg, #ff4b4b 0%, #ff0000 100%);
                    color: white; 
                    border: none; 
                    padding: 15px 20px; 
                    border-radius: 12px; 
                    font-weight: bold; 
                    font-size: 16px;
                    cursor: pointer; 
                    width: 100%; 
                    box-shadow: 0 4px 6px rgba(0,0,0,0.2);
                    touch-action: manipulation;
                    display: block;
                }}
                .mobile-launch-btn:active {{ transform: scale(0.98); background: #d60000; }}
                .warning-text {{
                    font-size: 12px; color: #856404; background-color: #fff3cd;
                    padding: 8px; border-radius: 6px; margin-bottom: 8px;
                    border: 1px solid #ffeeba; text-align: center;
                }}
            </style>
            </head>
            <body>
                <div class="warning-text">
                    üì± <b>iPhone:</b> ‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏¥‡∏î Block Pop-ups ‡πÉ‡∏ô Settings > Safari ‡∏Å‡πà‡∏≠‡∏ô
                </div>
                
                <button class="mobile-launch-btn" onclick="{js_command}">
                    üöÄ ‡πÄ‡∏õ‡∏¥‡∏î 9 ‡πÅ‡∏≠‡∏õ‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏£‡∏≤‡∏Ñ‡∏≤ (‡∏Å‡∏î‡∏ó‡∏µ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß)
                </button>
            </body>
            </html>
            """

            # 3. ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏î‡πâ‡∏ß‡∏¢ components.html (‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏π‡∏á‡πÉ‡∏´‡πâ‡∏û‡∏≠‡∏î‡∏µ‡∏Å‡∏±‡∏ö‡∏õ‡∏∏‡πà‡∏°)
            components.html(html_button, height=110)

            # -------------------------------------------------------
            # ‡∏à‡∏ö‡∏™‡πà‡∏ß‡∏ô‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç (‡∏õ‡∏∏‡πà‡∏°‡∏¢‡πà‡∏≠‡∏¢‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏õ‡∏•‡πà‡∏≠‡∏¢‡πÑ‡∏ß‡πâ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°)
            # -------------------------------------------------------
            cols = st.columns(2)
            # ...
                
            cols = st.columns(2)
            for i, s in enumerate(stores):
                    with cols[i%2]: st.link_button(f"üîç {s['name']}", s['url'], use_container_width=True)
        else:
            if query1: st.warning(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤: '{query1}'")

# =========================================================
# TAB 2: ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞ AI
# =========================================================
with tab2:
    st.info("üí° ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö: ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏ö‡∏ö‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ ‡πÄ‡∏ä‡πà‡∏ô '‡∏ó‡∏µ‡∏ß‡∏µ Samsung ‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡∏´‡∏°‡∏∑‡πà‡∏ô', '‡πÅ‡∏≠‡∏£‡πå inverter'")
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡πÉ‡∏´‡∏°‡πà
    processed_skus = df_mem['SKU'].astype(str).str.strip().tolist() if not df_mem.empty else []
    new_items_df = df_main[~df_main['‡∏£‡∏´‡∏±‡∏™‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤'].astype(str).str.strip().isin(processed_skus)]
    new_count = len(new_items_df)
    
    # --- ‡∏™‡πà‡∏ß‡∏ô‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏™‡∏°‡∏≠‡∏á AI ---
    with st.expander(f"‚öôÔ∏è ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏™‡∏°‡∏≠‡∏á AI ({len(df_mem)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÅ‡∏•‡πâ‡∏ß)"):
        c_a1, c_a2 = st.columns([3, 1])
        c_a1.write(f"‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà AI ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å: **{new_count}** ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
        
        # ‡∏õ‡∏∏‡πà‡∏°‡∏™‡∏≠‡∏ô AI
        # ‡∏õ‡∏∏‡πà‡∏°‡∏™‡∏≠‡∏ô AI
        if new_count > 0:
            if c_a2.button("üöÄ ‡∏™‡∏≠‡∏ô AI ‡πÄ‡∏î‡∏µ‡πã‡∏¢‡∏ß‡∏ô‡∏µ‡πâ", type="primary"):
                with st.status("ü§ñ AI ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ó‡∏≥‡∏á‡∏≤‡∏ô...", expanded=True) as status:
                    
                    # 1. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
                    if '‡∏ä‡∏ô‡∏¥‡∏î' not in new_items_df.columns: 
                        new_items_df['‡∏ä‡∏ô‡∏¥‡∏î'] = ''
                    
                    to_proc = new_items_df[['‡∏£‡∏´‡∏±‡∏™‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤', '‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤', '‡∏ä‡∏ô‡∏¥‡∏î']].rename(
                        columns={'‡∏£‡∏´‡∏±‡∏™‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤':'SKU', '‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤':'Name', '‡∏ä‡∏ô‡∏¥‡∏î':'Original_Kind'}
                    ).to_dict('records')

                    # ‚úÖ ‡∏™‡∏π‡∏ï‡∏£‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£: Batch 10
                    BATCH = 10
                    total_batches = (len(to_proc) // BATCH) + 1
                    
                    # 2. ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ß‡∏ô‡∏•‡∏π‡∏õ
                    for i in range(0, len(to_proc), BATCH):
                        chunk = to_proc[i:i+BATCH]
                        status.write(f"‚è≥ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• Batch {(i//BATCH)+1}/{total_batches} ({len(chunk)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)...")
                        
                        # ‡∏£‡∏ß‡∏°‡∏ä‡∏∑‡πà‡∏≠‡∏™‡πà‡∏á AI
                        names_for_ai = [f"{x['Name']} {x['Original_Kind']}" for x in chunk]
                        
                        # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å AI (‡∏ï‡∏±‡∏ß Retry 3 ‡∏£‡∏≠‡∏ö)
                        ai_res = ask_gemini_extract(names_for_ai)
                        
                        # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö String)
                        res_save = []
                        for idx, item in enumerate(chunk):
                            ar = ai_res[idx] if idx < len(ai_res) else {}
                            res_save.append([
                                str(item['SKU']).strip(),
                                str(ar.get('AI_Brand','Unknown')),
                                str(ar.get('AI_Type','Other')),
                                str(ar.get('AI_Spec','-')),
                                str(ar.get('AI_Tags','')),
                                str(ar.get('AI_Kind',''))
                            ])
                        
                        # 3. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÅ‡∏•‡∏∞‡∏•‡πâ‡∏≤‡∏á Cache ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ
                        if res_save:
                            try:
                                result = append_to_sheet(res_save)
                                if result:
                                    status.write(f"‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Batch {(i//BATCH)+1} ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
                                    st.cache_data.clear() # ‡∏•‡πâ‡∏≤‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥‡∏ó‡∏±‡∏ô‡∏ó‡∏µ‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏î‡πâ
                                else:
                                    status.error("‚ùå ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à (Google Sheet Error)")
                                    time.sleep(5) # ‡∏û‡∏±‡∏Å‡∏¢‡∏≤‡∏ß‡∏´‡∏ô‡πà‡∏≠‡∏¢‡∏ñ‡πâ‡∏≤ Error
                            except Exception as e:
                                status.error(f"‚ùå Error: {e}")
                        
                        # ‚úÖ ‡∏û‡∏±‡∏Å 3 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ (‡∏™‡∏π‡∏ï‡∏£‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£)
                        time.sleep(3)

                    # 4. ‡∏à‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô (‡∏≠‡∏¢‡∏π‡πà‡∏ô‡∏≠‡∏Å‡∏•‡∏π‡∏õ)
                    status.update(label="üéâ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô‡∏†‡∏≤‡∏£‡∏Å‡∏¥‡∏à!", state="complete")
                    st.success("‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢! ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏£‡∏µ‡πÇ‡∏´‡∏•‡∏î...")
                    time.sleep(2)
                    st.rerun()
        else:
            c_a2.button("üîÑ ‡∏£‡∏µ‡πÇ‡∏´‡∏•‡∏î", on_click=lambda: st.cache_data.clear())

        st.divider()
        st.write("üîß **‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏î‡∏π‡πÅ‡∏•‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•**")
        
        # ‡∏õ‡∏∏‡πà‡∏°‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡∏¢‡∏∞ (‡πÉ‡∏™‡πà key ‡∏Å‡∏±‡∏ô‡∏ã‡πâ‡∏≥ ‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏¢‡πà‡∏≠‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á)
        if st.button("üßπ ‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏¢‡∏∞ (‡∏•‡∏ö AI ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏à‡∏£‡∏¥‡∏á)", type="secondary", key="btn_cleanup_final"):
            with st.status("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î...", expanded=True) as status:
                valid_skus = df_main['‡∏£‡∏´‡∏±‡∏™‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤'].astype(str).str.strip().str.upper().unique()
                df_mem['check_key'] = df_mem['SKU'].astype(str).str.strip().str.upper()
                
                # ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏≠‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô Main
                df_mem_clean = df_mem[df_mem['check_key'].isin(valid_skus)].copy()
                # ‡∏•‡∏ö‡∏ï‡∏±‡∏ß‡∏ã‡πâ‡∏≥
                df_mem_clean = df_mem_clean.drop_duplicates(subset=['check_key'], keep='last')
                
                del df_mem_clean['check_key']
                
                deleted_count = len(df_mem) - len(df_mem_clean)
                
                if deleted_count > 0:
                    status.write(f"üóëÔ∏è ‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏¢‡∏∞/‡∏ï‡∏±‡∏ß‡∏ã‡πâ‡∏≥ {deleted_count} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£... ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏•‡∏ö")
                    success = overwrite_memory_sheet(df_mem_clean)
                    if success:
                        status.update(label="‚úÖ ‡∏•‡∏ö‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!", state="complete")
                        st.cache_data.clear()
                        time.sleep(2)
                        st.rerun()
                else:
                    status.update(label="‚úÖ ‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß", state="complete")

    st.divider()
    
    # --- ‡∏™‡πà‡∏ß‡∏ô‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ AI ---
    # -------------------------------------------------------------
    # ‡∏™‡πà‡∏ß‡∏ô‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ AI (‡∏â‡∏ö‡∏±‡∏ö‡∏≠‡∏±‡∏õ‡πÄ‡∏Å‡∏£‡∏î: ‡∏ï‡∏±‡∏î‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á + Debug Mode)
    # -------------------------------------------------------------
    
    # 1. ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡πÄ‡∏Ñ‡∏•‡∏µ‡∏¢‡∏£‡πå Cache ‡∏ñ‡πâ‡∏≤‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏ß‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï)
    df_search = merge_data(df_main, df_mem)
    
    # ‡∏Å‡∏±‡∏ô‡πÄ‡∏´‡∏ô‡∏µ‡∏¢‡∏ß: ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå AI_Kind ‡πÉ‡∏´‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ß‡πâ (‡πÅ‡∏ï‡πà‡∏ñ‡πâ‡∏≤ Cache ‡∏Ñ‡πâ‡∏≤‡∏á ‡∏°‡∏±‡∏ô‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡∏ß‡πà‡∏≤‡∏á‡∏ô‡∏∞)
    if 'AI_Kind' not in df_search.columns:
        df_search['AI_Kind'] = ''

    col_q1, col_q2 = st.columns([4, 1])
    query2 = col_q1.text_input("‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏ö‡∏ö‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥", placeholder="‡πÄ‡∏ä‡πà‡∏ô ‡∏ï‡∏π‡πâ‡πÄ‡∏¢‡πá‡∏ô 2 ‡∏õ‡∏£‡∏∞‡∏ï‡∏π ‡∏£‡∏≤‡∏Ñ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 8000", key="search_tab2")
    # -------------------------------------------------------------
    # ‡∏™‡πà‡∏ß‡∏ô‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ AI (‡∏â‡∏ö‡∏±‡∏ö Universal 100%: ‡πÉ‡∏ä‡πâ‡∏™‡πÄ‡∏Å‡∏•‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏Ñ‡∏±‡∏î‡∏Å‡∏£‡∏≠‡∏á)
    # -------------------------------------------------------------
    # -------------------------------------------------------------
    # üî• ‡∏™‡πà‡∏ß‡∏ô‡∏õ‡∏∏‡πà‡∏°‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ (‡∏â‡∏ö‡∏±‡∏ö‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ‡πÑ‡∏°‡πà‡πÄ‡∏á‡∏µ‡∏¢‡∏ö‡∏´‡∏≤‡∏¢‡πÅ‡∏ô‡πà‡∏ô‡∏≠‡∏ô)
    # -------------------------------------------------------------
    if col_q2.button("‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ AI", type="primary"):
        if query2:
            with st.spinner('ü§ñ AI ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡∏¥‡∏î...'):
                # 1. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÉ‡∏´‡πâ "‡∏ú‡πà‡∏≤‡∏ô‡∏´‡∏°‡∏î" ‡πÑ‡∏ß‡πâ‡∏Å‡πà‡∏≠‡∏ô (‡∏Å‡∏±‡∏ô‡πÄ‡∏´‡∏ô‡∏µ‡∏¢‡∏ß)
                final_mask = pd.Series([True] * len(df_search))
                active_conds = [] 
                
                try:
                    cols_ai = ['AI_Brand', 'AI_Type', 'AI_Spec', 'AI_Tags', '‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏∏‡∏ô‡∏ï‡πà‡∏≠‡∏´‡∏ô‡πà‡∏ß‡∏¢', 'AI_Kind']
                    result_json = ask_gemini_filter(query2, cols_ai, df_lookup=df_search)
                    
                    # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏î‡πâ JSON ‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤ ‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏≠‡∏á
                    if result_json and 'filters' in result_json:
                        filters = result_json['filters']
                        sort_order = result_json.get('sort_order')
                        
                        # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
                        text_search_cols = ['AI_Type', 'AI_Kind', 'AI_Tags', 'AI_Brand', '‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤']
                        
                        from collections import defaultdict
                        grouped_filters = defaultdict(list)
                        for f in filters: grouped_filters[f['column']].append(f)

                        # --- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ä‡πà‡∏ß‡∏¢ (Inner Functions) ---
                        def extract_numbers_universal(text):
                            try:
                                clean_text = str(text).replace(',', '')
                                nums = re.findall(r'(\d+\.?\d*)', clean_text)
                                if not nums: return []
                                return [float(n) for n in nums if n and n != '.']
                            except: return []

                        def validate_row(extracted_val, conditions):
                            if isinstance(extracted_val, list):
                                for num in extracted_val:
                                    pass_all = True
                                    for cond in conditions:
                                        op = cond['operator']
                                        limit = float(str(cond['value']).replace(',',''))
                                        if op == 'gt' and not (num > limit): pass_all = False; break
                                        if op == 'gte' and not (num >= limit): pass_all = False; break
                                        if op == 'lt' and not (num < limit): pass_all = False; break
                                        if op == 'lte' and not (num <= limit): pass_all = False; break
                                    if pass_all: return True
                                return False
                            else:
                                num = extracted_val
                                for cond in conditions:
                                    op = cond['operator']
                                    limit = float(str(cond['value']).replace(',',''))
                                    if op == 'gt' and not (num > limit): return False
                                    if op == 'gte' and not (num >= limit): return False
                                    if op == 'lt' and not (num < limit): return False
                                    if op == 'lte' and not (num <= limit): return False
                                return True

                       # --- ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ß‡∏≤‡∏á‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ (‡∏ï‡πà‡∏≠‡∏à‡∏≤‡∏Å return True ‡∏Ç‡∏≠‡∏á validate_row) ---

                        # --- ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ß‡∏ô‡∏•‡∏π‡∏õ‡∏Å‡∏£‡∏≠‡∏á (Logic ‡πÉ‡∏´‡∏°‡πà: ‡πÅ‡∏¢‡∏Å Range=AND, Text=OR) ---
                        for col_ai_suggested, conditions in grouped_filters.items():
                            if col_ai_suggested not in df_search.columns: continue

                            # 1. ‡πÅ‡∏¢‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç
                            numeric_conds = [f for f in conditions if f['operator'] in ['gt', 'gte', 'lt', 'lte']]
                            choice_conds = [f for f in conditions if f['operator'] not in ['gt', 'gte', 'lt', 'lte']]
                            
                            vals_log = [] 

                            # A. ‡∏Å‡∏£‡∏≠‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ä‡πà‡∏ß‡∏á (AND)
                            range_mask = pd.Series([True] * len(df_search))
                            if numeric_conds:
                                if col_ai_suggested == 'AI_Spec':
                                     vals = df_search[col_ai_suggested].apply(extract_numbers_universal)
                                else:
                                     vals = df_search[col_ai_suggested].apply(lambda x: extract_numbers_universal(x))
                                range_mask = vals.apply(lambda x: validate_row(x, numeric_conds))

                            # B. ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°/‡∏¢‡∏µ‡πà‡∏´‡πâ‡∏≠ (OR)
                            choice_mask = pd.Series([True] * len(df_search))
                            if choice_conds:
                                choice_mask = pd.Series([False] * len(df_search))
                                for f in choice_conds:
                                    t_val = str(f['value']).lower().strip().replace(" ", "")
                                    found_any = pd.Series([False] * len(df_search))
                                    for sc in text_search_cols:
                                        if sc in df_search.columns:
                                            d_clean = df_search[sc].fillna('').astype(str).str.lower().str.replace(" ", "")
                                            found_any |= d_clean.str.contains(t_val, na=False)
                                    choice_mask |= found_any
                                    vals_log.append(f"{t_val}")

                            # ‡∏£‡∏ß‡∏°‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢
                            final_mask &= (range_mask & choice_mask)
                            
                            if numeric_conds: active_conds.append(f"Range({col_ai_suggested})")
                            if choice_conds:  active_conds.append(f"Text({','.join(vals_log)})")
                        
                        # --- ‡∏à‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏≤‡∏á‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ (‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô else:) ---

                    else:
                        # ‡∏Å‡∏£‡∏ì‡∏µ AI ‡πÑ‡∏°‡πà‡∏ï‡∏≠‡∏ö JSON (Fallback) -> ‡∏´‡∏≤‡πÅ‡∏ö‡∏ö‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤
                        final_mask = df_search.astype(str).apply(lambda x: x.str.contains(query2, case=False)).any(axis=1)
                        active_conds.append("Keyword Search (Fallback)")

                except Exception as e:
                    st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
                    # ‡∏ñ‡πâ‡∏≤ Error ‡πÉ‡∏´‡πâ‡πÅ‡∏™‡∏î‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÑ‡∏õ‡πÄ‡∏•‡∏¢ ‡∏à‡∏∞‡πÑ‡∏î‡πâ‡∏£‡∏π‡πâ‡∏ß‡πà‡∏≤‡πÇ‡∏Ñ‡πâ‡∏î‡∏¢‡∏±‡∏á‡∏ß‡∏¥‡πà‡∏á‡∏≠‡∏¢‡∏π‡πà
                    final_mask = pd.Series([True] * len(df_search))

                # ---------------------------------------------------------
                # ‡∏™‡πà‡∏ß‡∏ô‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• (‡∏≠‡∏¢‡∏π‡πà‡∏ô‡∏≠‡∏Å try/except ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÄ‡∏™‡∏°‡∏≠)
                # ---------------------------------------------------------
                results = df_search[final_mask]
                
                # Debug ‡πÄ‡∏•‡πá‡∏Å‡πÜ: ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ ‡πÉ‡∏´‡πâ‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤ mask ‡πÄ‡∏´‡∏•‡∏∑‡∏≠ 0
                if results.empty:
                    st.warning(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ï‡∏≤‡∏°‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç: {'; '.join(active_conds)}")
                    st.caption("üîç ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥: ‡∏•‡∏≠‡∏á‡∏•‡∏î‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏Å‡∏ß‡πâ‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô")
                else:
                    st.success(f"‚úÖ ‡∏û‡∏ö {len(results)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ (‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç: {'; '.join(active_conds)})")
                    st.dataframe(
                        results[['‡∏£‡∏´‡∏±‡∏™‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤', '‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤', '‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏∏‡∏ô‡∏ï‡πà‡∏≠‡∏´‡∏ô‡πà‡∏ß‡∏¢', '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏ï‡πâ‡∏≠‡∏Å', 'AI_Brand', 'AI_Spec', 'AI_Kind', 'AI_Tags']],
                        column_config={
                            "‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏∏‡∏ô‡∏ï‡πà‡∏≠‡∏´‡∏ô‡πà‡∏ß‡∏¢": st.column_config.NumberColumn("‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏∏‡∏ô", format="‡∏ø%d"), 
                            "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏ï‡πâ‡∏≠‡∏Å": st.column_config.ProgressColumn("‡∏™‡∏ï‡πâ‡∏≠‡∏Å", format="%d", max_value=100)
                        },
                        use_container_width=True, hide_index=True
                    )
